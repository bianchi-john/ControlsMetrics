{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5e640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import ndcg_score\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Caricamento e preparazione dati\n",
    "def prepare_data(unified_df):\n",
    "    # Estrai tutti i codici unici per stratificazione\n",
    "    unified_df['combined_labels'] = unified_df['eucs_code'] + '|' + unified_df['secNumCloud_id']\n",
    "    \n",
    "    # Prepara il testo\n",
    "    unified_df['full_text'] = (\n",
    "        unified_df['api_name'].fillna('') + ' ' +\n",
    "        unified_df['description'].fillna('') + ' ' +\n",
    "        unified_df['cisco_title'].fillna('')\n",
    "    )\n",
    "    \n",
    "    # Binarizza le etichette per NDCG\n",
    "    mlb_eucs = MultiLabelBinarizer()\n",
    "    mlb_secnum = MultiLabelBinarizer()\n",
    "    \n",
    "    # Crea liste di etichette\n",
    "    eucs_labels = [label.split(',') for label in unified_df['eucs_code']]\n",
    "    secnum_labels = [[label] for label in unified_df['secNumCloud_id']]\n",
    "    \n",
    "    # Adatta i binarizzatori\n",
    "    eucs_binary = mlb_eucs.fit_transform(eucs_labels)\n",
    "    secnum_binary = mlb_secnum.fit_transform(secnum_labels)\n",
    "    \n",
    "    return {\n",
    "        'texts': unified_df['full_text'].values,\n",
    "        'eucs_labels': eucs_binary,\n",
    "        'secnum_labels': secnum_binary,\n",
    "        'mlb_eucs': mlb_eucs,\n",
    "        'mlb_secnum': mlb_secnum,\n",
    "        'combined_labels': unified_df['combined_labels'].values\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a567d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SecurityControlModel(tf.keras.Model):\n",
    "    def __init__(self, num_eucs_classes, num_secnum_classes):\n",
    "        super().__init__()\n",
    "        self.bert = TFBertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.dropout = tf.keras.layers.Dropout(0.3)\n",
    "        self.eucs_classifier = tf.keras.layers.Dense(num_eucs_classes, activation='sigmoid')\n",
    "        self.secnum_classifier = tf.keras.layers.Dense(num_secnum_classes, activation='sigmoid')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_ids, attention_mask = inputs\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        eucs_logits = self.eucs_classifier(pooled_output)\n",
    "        secnum_logits = self.secnum_classifier(pooled_output)\n",
    "        \n",
    "        return eucs_logits, secnum_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd72a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SecurityDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, texts, eucs_labels, secnum_labels, tokenizer, batch_size=8, max_len=256):\n",
    "        self.texts = texts\n",
    "        self.eucs_labels = eucs_labels\n",
    "        self.secnum_labels = secnum_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_len = max_len\n",
    "        self.indices = np.arange(len(texts))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.texts) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        batch_texts = [self.texts[i] for i in batch_indices]\n",
    "        \n",
    "        encodings = self.tokenizer(\n",
    "            batch_texts,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        \n",
    "        batch_eucs = self.eucs_labels[batch_indices]\n",
    "        batch_secnum = self.secnum_labels[batch_indices]\n",
    "        \n",
    "        return (encodings['input_ids'], encodings['attention_mask']), (batch_eucs, batch_secnum)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ffe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(data, num_folds=10):\n",
    "    # Inizializzazione tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    \n",
    "    # Preparazione per cross-validation\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(data['texts'], data['combined_labels'])):\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"Training Fold {fold+1}/{num_folds}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        # Split dati\n",
    "        train_texts = data['texts'][train_idx]\n",
    "        val_texts = data['texts'][val_idx]\n",
    "        \n",
    "        train_eucs = data['eucs_labels'][train_idx]\n",
    "        val_eucs = data['eucs_labels'][val_idx]\n",
    "        \n",
    "        train_secnum = data['secnum_labels'][train_idx]\n",
    "        val_secnum = data['secnum_labels'][val_idx]\n",
    "        \n",
    "        # Creazione dataset\n",
    "        train_dataset = SecurityDataset(\n",
    "            train_texts, train_eucs, train_secnum, tokenizer, batch_size=8\n",
    "        )\n",
    "        \n",
    "        val_dataset = SecurityDataset(\n",
    "            val_texts, val_eucs, val_secnum, tokenizer, batch_size=8\n",
    "        )\n",
    "        \n",
    "        # Inizializzazione modello\n",
    "        model = SecurityControlModel(\n",
    "            num_eucs_classes=data['eucs_labels'].shape[1],\n",
    "            num_secnum_classes=data['secnum_labels'].shape[1]\n",
    "        )\n",
    "        \n",
    "        # Compilazione modello\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "            loss={\n",
    "                'output_1': tf.keras.losses.BinaryCrossentropy(),\n",
    "                'output_2': tf.keras.losses.BinaryCrossentropy()\n",
    "            },\n",
    "            loss_weights=[0.7, 0.3],  # Ponderazione per EUCS vs SecNumCloud\n",
    "            metrics={\n",
    "                'output_1': [\n",
    "                    tf.keras.metrics.Precision(name='precision'),\n",
    "                    tf.keras.metrics.Recall(name='recall'),\n",
    "                    tf.keras.metrics.AUC(name='auc')\n",
    "                ],\n",
    "                'output_2': [\n",
    "                    tf.keras.metrics.Precision(name='precision'),\n",
    "                    tf.keras.metrics.Recall(name='recall'),\n",
    "                    tf.keras.metrics.AUC(name='auc')\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                patience=3,\n",
    "                restore_best_weights=True,\n",
    "                monitor='val_output_1_auc'\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.1,\n",
    "                patience=2\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Addestramento\n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data=val_dataset,\n",
    "            epochs=15,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Valutazione sul validation set\n",
    "        val_preds = model.predict(val_dataset)\n",
    "        \n",
    "        # Calcolo NDCG per EUCS\n",
    "        eucs_ndcg = ndcg_score(val_eucs, val_preds[0], k=10)\n",
    "        \n",
    "        # Calcolo NDCG per SecNumCloud\n",
    "        secnum_ndcg = ndcg_score(val_secnum, val_preds[1], k=10)\n",
    "        \n",
    "        # Calcolo Precision-Recall AUC per EUCS\n",
    "        eucs_auc = tf.keras.metrics.AUC(curve='PR')(\n",
    "            val_eucs, val_preds[0]\n",
    "        ).numpy()\n",
    "        \n",
    "        # Calcolo Precision-Recall AUC per SecNumCloud\n",
    "        secnum_auc = tf.keras.metrics.AUC(curve='PR')(\n",
    "            val_secnum, val_preds[1]\n",
    "        ).numpy()\n",
    "        \n",
    "        # Salvataggio risultati\n",
    "        fold_results.append({\n",
    "            'fold': fold+1,\n",
    "            'eucs_ndcg': eucs_ndcg,\n",
    "            'secnum_ndcg': secnum_ndcg,\n",
    "            'eucs_auc': eucs_auc,\n",
    "            'secnum_auc': secnum_auc,\n",
    "            'history': history.history\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nFold {fold+1} Results:\")\n",
    "        print(f\"EUCS NDCG@10: {eucs_ndcg:.4f}\")\n",
    "        print(f\"SecNumCloud NDCG@10: {secnum_ndcg:.4f}\")\n",
    "        print(f\"EUCS PR-AUC: {eucs_auc:.4f}\")\n",
    "        print(f\"SecNumCloud PR-AUC: {secnum_auc:.4f}\")\n",
    "    \n",
    "    return fold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f252c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_dataset, mlb_eucs, mlb_secnum):\n",
    "    # Previsioni sul test set\n",
    "    test_preds = model.predict(test_dataset)\n",
    "    \n",
    "    # Calcolo NDCG a diversi k\n",
    "    ndcg_results = {}\n",
    "    for k in [1, 3, 5, 10]:\n",
    "        eucs_ndcg = ndcg_score(test_dataset.eucs_labels, test_preds[0], k=k)\n",
    "        secnum_ndcg = ndcg_score(test_dataset.secnum_labels, test_preds[1], k=k)\n",
    "        ndcg_results[f'eucs_ndcg@{k}'] = eucs_ndcg\n",
    "        ndcg_results[f'secnum_ndcg@{k}'] = secnum_ndcg\n",
    "    \n",
    "    # Calcolo Precision-Recall AUC\n",
    "    eucs_auc = tf.keras.metrics.AUC(curve='PR')(\n",
    "        test_dataset.eucs_labels, test_preds[0]\n",
    "    ).numpy()\n",
    "    \n",
    "    secnum_auc = tf.keras.metrics.AUC(curve='PR')(\n",
    "        test_dataset.secnum_labels, test_preds[1]\n",
    "    ).numpy()\n",
    "    \n",
    "    # Calcolo F1-score\n",
    "    eucs_f1 = f1_score(\n",
    "        test_dataset.eucs_labels, \n",
    "        test_preds[0] > 0.5, \n",
    "        average='samples'\n",
    "    )\n",
    "    \n",
    "    secnum_f1 = f1_score(\n",
    "        test_dataset.secnum_labels, \n",
    "        test_preds[1] > 0.5, \n",
    "        average='samples'\n",
    "    )\n",
    "    \n",
    "    # Calcolo Hamming Loss\n",
    "    eucs_hamming = hamming_loss(\n",
    "        test_dataset.eucs_labels, \n",
    "        test_preds[0] > 0.5\n",
    "    )\n",
    "    \n",
    "    secnum_hamming = hamming_loss(\n",
    "        test_dataset.secnum_labels, \n",
    "        test_preds[1] > 0.5\n",
    "    )\n",
    "    \n",
    "    # Metriche di ranking\n",
    "    coverage = {}\n",
    "    for k in [3, 5, 10]:\n",
    "        # Per EUCS\n",
    "        top_k_preds = np.argsort(test_preds[0], axis=1)[:, -k:]\n",
    "        coverage[f'eucs_coverage@{k}'] = coverage_error(\n",
    "            test_dataset.eucs_labels, \n",
    "            test_preds[0], \n",
    "            top_k=top_k_preds\n",
    "        )\n",
    "        \n",
    "        # Per SecNumCloud\n",
    "        top_k_preds = np.argsort(test_preds[1], axis=1)[:, -k:]\n",
    "        coverage[f'secnum_coverage@{k}'] = coverage_error(\n",
    "            test_dataset.secnum_labels, \n",
    "            test_preds[1], \n",
    "            top_k=top_k_preds\n",
    "        )\n",
    "    \n",
    "    return {\n",
    "        'ndcg': ndcg_results,\n",
    "        'auc': {'eucs': eucs_auc, 'secnum': secnum_auc},\n",
    "        'f1': {'eucs': eucs_f1, 'secnum': secnum_f1},\n",
    "        'hamming_loss': {'eucs': eucs_hamming, 'secnum': secnum_hamming},\n",
    "        'coverage': coverage\n",
    "    }\n",
    "\n",
    "def coverage_error(y_true, y_pred, top_k):\n",
    "    \"\"\"\n",
    "    Calcola la copertura: quanti label rilevanti sono stati recuperati nel top-k\n",
    "    \"\"\"\n",
    "    coverage_scores = []\n",
    "    for i in range(len(y_true)):\n",
    "        true_labels = set(np.where(y_true[i] == 1)[0])\n",
    "        predicted_labels = set(top_k[i])\n",
    "        coverage_scores.append(len(true_labels & predicted_labels) / len(true_labels) if len(true_labels) > 0 else 0)\n",
    "    \n",
    "    return np.mean(coverage_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47623527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_training_pipeline(unified_df):\n",
    "    # Preparazione dati\n",
    "    data = prepare_data(unified_df)\n",
    "    \n",
    "    # Addestramento con 10-fold cross-validation\n",
    "    fold_results = train_and_evaluate(data, num_folds=10)\n",
    "    \n",
    "    # Analisi dei risultati\n",
    "    avg_metrics = {\n",
    "        'eucs_ndcg': np.mean([r['eucs_ndcg'] for r in fold_results]),\n",
    "        'secnum_ndcg': np.mean([r['secnum_ndcg'] for r in fold_results]),\n",
    "        'eucs_auc': np.mean([r['eucs_auc'] for r in fold_results]),\n",
    "        'secnum_auc': np.mean([r['secnum_auc'] for r in fold_results])\n",
    "    }\n",
    "    \n",
    "    print(\"\\nFinal Average Metrics:\")\n",
    "    print(f\"EUCS NDCG@10: {avg_metrics['eucs_ndcg']:.4f}\")\n",
    "    print(f\"SecNumCloud NDCG@10: {avg_metrics['secnum_ndcg']:.4f}\")\n",
    "    print(f\"EUCS PR-AUC: {avg_metrics['eucs_auc']:.4f}\")\n",
    "    print(f\"SecNumCloud PR-AUC: {avg_metrics['secnum_auc']:.4f}\")\n",
    "    \n",
    "    # Addestramento del modello finale su tutti i dati\n",
    "    print(\"\\nTraining final model on full dataset...\")\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    full_dataset = SecurityDataset(\n",
    "        data['texts'], \n",
    "        data['eucs_labels'], \n",
    "        data['secnum_labels'], \n",
    "        tokenizer\n",
    "    )\n",
    "    \n",
    "    final_model = SecurityControlModel(\n",
    "        num_eucs_classes=data['eucs_labels'].shape[1],\n",
    "        num_secnum_classes=data['secnum_labels'].shape[1]\n",
    "    )\n",
    "    \n",
    "    final_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.Precision(name='precision'),\n",
    "            tf.keras.metrics.Recall(name='recall'),\n",
    "            tf.keras.metrics.AUC(name='auc')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    final_model.fit(\n",
    "        full_dataset,\n",
    "        epochs=10,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Salvataggio del modello finale\n",
    "    final_model.save('security_control_model')\n",
    "    data['mlb_eucs'].dump('mlb_eucs.pkl')\n",
    "    data['mlb_secnum'].dump('mlb_secnum.pkl')\n",
    "    \n",
    "    print(\"Final model saved successfully!\")\n",
    "    \n",
    "    return final_model, data, fold_results, avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59264fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SecurityControlPredictor:\n",
    "    def __init__(self, model_path, mlb_eucs_path, mlb_secnum_path):\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        self.mlb_eucs = joblib.load(mlb_eucs_path)\n",
    "        self.mlb_secnum = joblib.load(mlb_secnum_path)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    \n",
    "    def predict(self, text, top_k=5):\n",
    "        # Tokenizzazione\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=256,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        \n",
    "        # Previsione\n",
    "        eucs_probs, secnum_probs = self.model.predict([\n",
    "            encoding['input_ids'],\n",
    "            encoding['attention_mask']\n",
    "        ])\n",
    "        \n",
    "        # Processamento risultati EUCS\n",
    "        eucs_indices = np.argsort(eucs_probs[0])[::-1][:top_k]\n",
    "        eucs_results = []\n",
    "        for idx in eucs_indices:\n",
    "            code = self.mlb_eucs.classes_[idx]\n",
    "            prob = eucs_probs[0][idx]\n",
    "            eucs_results.append({'code': code, 'probability': float(prob)})\n",
    "        \n",
    "        # Processamento risultati SecNumCloud\n",
    "        secnum_indices = np.argsort(secnum_probs[0])[::-1][:top_k]\n",
    "        secnum_results = []\n",
    "        for idx in secnum_indices:\n",
    "            code = self.mlb_secnum.classes_[idx]\n",
    "            prob = secnum_probs[0][idx]\n",
    "            secnum_results.append({'code': code, 'probability': float(prob)})\n",
    "        \n",
    "        return {\n",
    "            'eucs_predictions': eucs_results,\n",
    "            'secnum_predictions': secnum_results,\n",
    "            'combined_confidence': self._calculate_confidence(eucs_probs, secnum_probs)\n",
    "        }\n",
    "    \n",
    "    def _calculate_confidence(self, eucs_probs, secnum_probs):\n",
    "        \"\"\"Calcola una metrica di confidenza combinata\"\"\"\n",
    "        # Media della probabilit√† massima per ciascun task\n",
    "        eucs_max = np.max(eucs_probs)\n",
    "        secnum_max = np.max(secnum_probs)\n",
    "        return float((eucs_max + secnum_max) / 2)\n",
    "    \n",
    "    def evaluate_ndcg(self, test_data, k=10):\n",
    "        \"\"\"Valuta NDCG su un dataset di test\"\"\"\n",
    "        test_texts = test_data['texts']\n",
    "        true_eucs = test_data['eucs_labels']\n",
    "        true_secnum = test_data['secnum_labels']\n",
    "        \n",
    "        pred_eucs = []\n",
    "        pred_secnum = []\n",
    "        \n",
    "        # Genera previsioni per tutti i test samples\n",
    "        for text in tqdm(test_texts):\n",
    "            encoding = self.tokenizer(\n",
    "                text,\n",
    "                max_length=256,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='tf'\n",
    "            )\n",
    "            eucs_prob, secnum_prob = self.model.predict([\n",
    "                encoding['input_ids'],\n",
    "                encoding['attention_mask']\n",
    "            ])\n",
    "            pred_eucs.append(eucs_prob[0])\n",
    "            pred_secnum.append(secnum_prob[0])\n",
    "        \n",
    "        # Calcolo NDCG\n",
    "        eucs_ndcg = ndcg_score(true_eucs, np.array(pred_eucs), k=k)\n",
    "        secnum_ndcg = ndcg_score(true_secnum, np.array(pred_secnum), k=k)\n",
    "        \n",
    "        return {\n",
    "            'eucs_ndcg': eucs_ndcg,\n",
    "            'secnum_ndcg': secnum_ndcg,\n",
    "            'average_ndcg': (eucs_ndcg + secnum_ndcg) / 2\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cba1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento dei dati\n",
    "unified_df = pd.read_csv('Output/unified_data.csv')\n",
    "\n",
    "# Esecuzione della pipeline\n",
    "final_model, prepared_data, fold_results, avg_metrics = full_training_pipeline(unified_df)\n",
    "\n",
    "# Inizializzazione del predictor\n",
    "predictor = SecurityControlPredictor(\n",
    "    'security_control_model',\n",
    "    'mlb_eucs.pkl',\n",
    "    'mlb_secnum.pkl'\n",
    ")\n",
    "\n",
    "# Esempio di utilizzo\n",
    "new_control = \"Gestione sicura degli account utente e controllo degli accessi\"\n",
    "prediction = predictor.predict(new_control)\n",
    "\n",
    "print(\"\\nPrediction Results:\")\n",
    "print(\"EUCS Codes:\")\n",
    "for item in prediction['eucs_predictions']:\n",
    "    print(f\"  {item['code']}: {item['probability']:.4f}\")\n",
    "\n",
    "print(\"\\nSecNumCloud Codes:\")\n",
    "for item in prediction['secnum_predictions']:\n",
    "    print(f\"  {item['code']}: {item['probability']:.4f}\")\n",
    "\n",
    "# Valutazione NDCG sul test set (se disponibile)\n",
    "if 'test_data' in locals():\n",
    "    ndcg_eval = predictor.evaluate_ndcg(test_data)\n",
    "    print(f\"\\nNDCG Evaluation: EUCS={ndcg_eval['eucs_ndcg']:.4f}, SecNumCloud={ndcg_eval['secnum_ndcg']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
