{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ac70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cbd8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses, models, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "\n",
    "# --- 1. CONFIGURAZIONE ---\n",
    "model_name = 'all-MiniLM-L6-v2'  # Il modello base\n",
    "train_batch_size = 16            # Numero di coppie per batch (più alto è meglio per questa Loss, ma occhio alla memoria)\n",
    "num_epochs = 4                   # Numero di passaggi sui dati (non esagerare per evitare overfitting su dataset piccoli)\n",
    "model_save_path = 'FineTunedModel/fine_tuned_compliance_model' # Cartella dove salvare il modello\n",
    "csv_file = 'TrainAndTestData/training.csv' # Il file generato nello step precedente\n",
    "\n",
    "# Verifica esistenza file\n",
    "if not os.path.exists(csv_file):\n",
    "    raise FileNotFoundError(f\"Il file {csv_file} non esiste! Esegui prima il codice di generazione dati.\")\n",
    "\n",
    "# --- 2. CARICAMENTO DATI ---\n",
    "print(\"Caricamento dataset...\")\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Convertiamo il DataFrame in una lista di oggetti InputExample\n",
    "train_examples = []\n",
    "for i, row in df.iterrows():\n",
    "    # InputExample accetta una lista di testi. Qui ne passiamo due: [Anchor, Positive]\n",
    "    train_examples.append(InputExample(texts=[str(row['anchor']), str(row['positive'])]))\n",
    "\n",
    "print(f\"Dataset caricato: {len(train_examples)} coppie di training.\")\n",
    "\n",
    "# Creazione del DataLoader\n",
    "# Shuffle è importante!\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "# --- 3. INIZIALIZZAZIONE MODELLO ---\n",
    "print(f\"Scaricamento modello base: {model_name}...\")\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# --- 4. DEFINIZIONE DELLA LOSS FUNCTION ---\n",
    "# MultipleNegativesRankingLoss è ottima quando hai solo coppie positive.\n",
    "# Usa gli altri campioni nel batch come negativi impliciti.\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "\n",
    "# --- 5. CALCOLO PASSI DI WARMUP ---\n",
    "# Il warmup aiuta a stabilizzare il training all'inizio\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) # 10% del training\n",
    "\n",
    "# --- 6. TRAINING ---\n",
    "print(\"Inizio del fine-tuning...\")\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    show_progress_bar=True,\n",
    "    output_path=model_save_path # Salva automaticamente qui alla fine\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Training completato! Il modello è stato salvato in: '{model_save_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
