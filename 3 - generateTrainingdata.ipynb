{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "591027f2",
   "metadata": {},
   "source": [
    "# Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c684b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ CARICAMENTO DATI\n",
      "============================================================\n",
      "ðŸ“‚ Caricamento Cisco.csv...\n",
      "ðŸ“‚ Caricamento SpanishENS.csv...\n",
      "ðŸ“‚ Caricamento SecNumCloud...\n",
      "ðŸ“‚ Caricamento EUCS MEDINA...\n",
      "ðŸ“‚ Caricamento Fabasoft Metrics...\n",
      "\n",
      "âœ… Tutti i file caricati con successo!\n",
      "\n",
      "\n",
      "ðŸ”— PROCESSING CISCO MAPPINGS\n",
      "============================================================\n",
      "âœ“ Cisco processato: 181 righe generate\n",
      "\n",
      "ðŸ”— PROCESSING EUCS MEDINA MAPPINGS\n",
      "============================================================\n",
      "âœ“ EUCS MEDINA processato: 78 righe generate\n",
      "\n",
      "ðŸ”— PROCESSING FABASOFT METRICS MAPPINGS\n",
      "============================================================\n",
      "âœ“ Fabasoft processato: 11 righe generate\n",
      "\n",
      "ðŸ“Š CREAZIONE TRAINING DATAFRAME\n",
      "============================================================\n",
      "âœ“ Training set creato: 278 righe\n",
      "\n",
      "ðŸ” VALIDAZIONE MAPPINGS\n",
      "============================================================\n",
      "\n",
      "1. Controllo Aggregazione SecNumCloud (Top 5 righe):\n",
      "\n",
      "   Source: [Cisco] CCF 1\n",
      "   Target ID Composite: 18.2.1.a | 18.3.a | 18.4.a\n",
      "   Target Text Start: The service provider must document and implement an audit program over three years defining the peri...\n",
      "\n",
      "   Source: [Cisco] CCF 2\n",
      "   Target ID Composite: 12.1.a\n",
      "   Target Text Start: The service provider must document the operating procedures, keep them up to date and make them acce...\n",
      "\n",
      "   Source: [Cisco] CCF 4\n",
      "   Target ID Composite: 18.2.1.a\n",
      "   Target Text Start: The service provider must document and implement an audit program over three years defining the peri...\n",
      "\n",
      "   Source: [Cisco] CCF 8\n",
      "   Target ID Composite: 18.1.a | 18.1.c | 18.1.e\n",
      "   Target Text Start: The service provider must identify the legal, regulatory and contractual requirements in force appli...\n",
      "\n",
      "   Source: [Cisco] CCF 10\n",
      "   Target ID Composite: 11.2.1.c | 11.2.2.c | 17.1.a | 17.1.b | 17.2.a | 17.3.a\n",
      "   Target Text Start: The service provider must define and document derogatory physical access measures in an emergency. T...\n",
      "\n",
      "ðŸ’¾ Training set salvato in: TrainAndTestData/trainData/training_set_control_mappings.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from typing import List, Tuple, Set\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# File paths\n",
    "FILES = {\n",
    "    'cisco': 'Cisco.csv',\n",
    "    'spanish_ens': 'SpanishENS.csv',\n",
    "    'secnumcloud': 'Secnumcloud.csv',\n",
    "    'bsi_c5': 'BSI-C5.json',\n",
    "    'old_eucs': 'OldEucsRequirements.csv',\n",
    "    'new_eucs': 'NewEucsRequirements_with_texts.csv',\n",
    "    'medina_metrics': 'medinaMetrics.csv',\n",
    "    'fabasoft_metrics': 'fabasoftMetrics.csv'\n",
    "}\n",
    "\n",
    "# Output files\n",
    "OUTPUT = {\n",
    "    'train': 'training_dataset.csv',\n",
    "    'test': 'test_dataset.csv'\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def standardize_id(control_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Standardize control IDs by removing extra whitespace and normalizing format.\n",
    "    Examples:\n",
    "    - \"OPS-05.3H \" -> \"OPS-05.3H\"\n",
    "    - \"OIS-01 \" -> \"OIS-01\"\n",
    "    - \" BSI C5 OPS-22\" -> \"OPS-22\"\n",
    "    \"\"\"\n",
    "    if pd.isna(control_id) or control_id == '':\n",
    "        return ''\n",
    "    \n",
    "    # Convert to string and strip whitespace\n",
    "    control_id = str(control_id).strip()\n",
    "    \n",
    "    # Remove \"BSI C5 \" prefix if present\n",
    "    control_id = re.sub(r'^BSI\\s+C5\\s+', '', control_id, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove extra internal whitespace\n",
    "    control_id = re.sub(r'\\s+', ' ', control_id)\n",
    "    \n",
    "    return control_id\n",
    "\n",
    "def parse_control_ids(value: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parse a string containing multiple control IDs separated by commas or newlines.\n",
    "    Returns a list of standardized IDs.\n",
    "    \"\"\"\n",
    "    if pd.isna(value) or value == '':\n",
    "        return []\n",
    "    \n",
    "    # Split by comma or newline\n",
    "    ids = re.split(r'[,\\n]+', str(value))\n",
    "    \n",
    "    # Standardize each ID and filter out empty strings\n",
    "    standardized = [standardize_id(id_str) for id_str in ids]\n",
    "    return [id_str for id_str in standardized if id_str]\n",
    "\n",
    "def create_pairs(source_id: str, source_text: str, target_ids: List[str], \n",
    "                 target_texts: dict, label: int = 1) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Create training/test pairs from source control to target controls.\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    for target_id in target_ids:\n",
    "        if target_id in target_texts:\n",
    "            pairs.append({\n",
    "                'source_id': source_id,\n",
    "                'source_text': source_text,\n",
    "                'target_id': target_id,\n",
    "                'target_text': target_texts[target_id],\n",
    "                'label': label\n",
    "            })\n",
    "    return pairs\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Loading data files...\")\n",
    "\n",
    "# Load Cisco CSV\n",
    "cisco_df = pd.read_csv(FILES['cisco'], encoding='utf-8')\n",
    "print(f\"âœ“ Loaded Cisco.csv: {len(cisco_df)} rows\")\n",
    "\n",
    "# Load Spanish ENS\n",
    "spanish_ens_df = pd.read_csv(FILES['spanish_ens'], encoding='utf-8')\n",
    "spanish_ens_dict = dict(zip(\n",
    "    spanish_ens_df['Control ID'].apply(standardize_id),\n",
    "    spanish_ens_df['Description']\n",
    "))\n",
    "print(f\"âœ“ Loaded SpanishENS.csv: {len(spanish_ens_dict)} controls\")\n",
    "\n",
    "# Load SecNumCloud\n",
    "secnumcloud_df = pd.read_csv(FILES['secnumcloud'], encoding='utf-8')\n",
    "secnumcloud_dict = dict(zip(\n",
    "    secnumcloud_df['ID'].apply(standardize_id),\n",
    "    secnumcloud_df['Description_EN']\n",
    "))\n",
    "print(f\"âœ“ Loaded Secnumcloud.csv: {len(secnumcloud_dict)} controls\")\n",
    "\n",
    "# Load BSI-C5 JSON\n",
    "with open(FILES['bsi_c5'], 'r', encoding='utf-8') as f:\n",
    "    bsi_c5_data = json.load(f)\n",
    "\n",
    "bsi_c5_dict = {}\n",
    "for control in bsi_c5_data:\n",
    "    code = standardize_id(control.get('code', ''))\n",
    "    if code and code != 'AAA-00':  # Skip generic control\n",
    "        desc = control.get('descriptionTitle', '')\n",
    "        if desc:\n",
    "            bsi_c5_dict[code] = desc\n",
    "print(f\"âœ“ Loaded BSI-C5.json: {len(bsi_c5_dict)} controls\")\n",
    "\n",
    "# Load Old EUCS Requirements\n",
    "old_eucs_df = pd.read_csv(FILES['old_eucs'], encoding='utf-8')\n",
    "old_eucs_dict = dict(zip(\n",
    "    old_eucs_df['controlId'].apply(standardize_id),\n",
    "    old_eucs_df['description']\n",
    "))\n",
    "old_eucs_ids = set(old_eucs_dict.keys())\n",
    "print(f\"âœ“ Loaded OldEucsRequirements.csv: {len(old_eucs_dict)} controls\")\n",
    "\n",
    "# Load New EUCS Requirements\n",
    "new_eucs_df = pd.read_csv(FILES['new_eucs'], encoding='utf-8')\n",
    "new_eucs_dict = {}\n",
    "new_eucs_to_bsi = {}\n",
    "new_eucs_to_secnum = {}\n",
    "new_eucs_to_iso27002 = {}\n",
    "new_eucs_to_iso27017 = {}\n",
    "\n",
    "for _, row in new_eucs_df.iterrows():\n",
    "    eucs_id = standardize_id(row['EUCS Ref (Detailed)'])\n",
    "    eucs_text = row['EUCS Text']\n",
    "    \n",
    "    if eucs_id and pd.notna(eucs_text):\n",
    "        new_eucs_dict[eucs_id] = eucs_text\n",
    "        \n",
    "        # Parse mappings\n",
    "        bsi_ids = parse_control_ids(row.get('C5.2020 GERMANY ', ''))\n",
    "        secnum_ids = parse_control_ids(row.get('SecNumCloud FRANCE ', ''))\n",
    "        iso27002_ids = parse_control_ids(row.get('ISO 27002 ', ''))\n",
    "        iso27017_ids = parse_control_ids(row.get('ISO 27017 ', ''))\n",
    "        \n",
    "        if bsi_ids:\n",
    "            new_eucs_to_bsi[eucs_id] = bsi_ids\n",
    "        if secnum_ids:\n",
    "            new_eucs_to_secnum[eucs_id] = secnum_ids\n",
    "        if iso27002_ids:\n",
    "            new_eucs_to_iso27002[eucs_id] = iso27002_ids\n",
    "        if iso27017_ids:\n",
    "            new_eucs_to_iso27017[eucs_id] = iso27017_ids\n",
    "\n",
    "print(f\"âœ“ Loaded NewEucsRequirements.csv: {len(new_eucs_dict)} controls\")\n",
    "print(f\"  - BSI-C5 mappings: {len(new_eucs_to_bsi)}\")\n",
    "print(f\"  - SecNumCloud mappings: {len(new_eucs_to_secnum)}\")\n",
    "\n",
    "# Load Medina Metrics\n",
    "medina_df = pd.read_csv(FILES['medina_metrics'], encoding='utf-8')\n",
    "medina_dict = {}\n",
    "for _, row in medina_df.iterrows():\n",
    "    metric_id = str(row['ID'])\n",
    "    metric_desc = row['description']\n",
    "    medina_dict[metric_id] = metric_desc\n",
    "print(f\"âœ“ Loaded medinaMetrics.csv: {len(medina_df)} metrics\")\n",
    "\n",
    "# Load Fabasoft Metrics\n",
    "fabasoft_df = pd.read_csv(FILES['fabasoft_metrics'], encoding='utf-8')\n",
    "fabasoft_dict = {}\n",
    "for _, row in fabasoft_df.iterrows():\n",
    "    metric_id = row['ID']\n",
    "    if pd.notna(metric_id):\n",
    "        metric_desc = row['Description']\n",
    "        fabasoft_dict[metric_id] = metric_desc\n",
    "print(f\"âœ“ Loaded fabasoftMetrics.csv: {len(fabasoft_dict)} metrics\")\n",
    "\n",
    "# ============================================================================\n",
    "# GENERATE TRAINING DATASET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING TRAINING DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "training_pairs = []\n",
    "\n",
    "# 1. SpanishENS â†” Cisco\n",
    "print(\"\\n1. Processing SpanishENS â†” Cisco...\")\n",
    "for _, row in cisco_df.iterrows():\n",
    "    cisco_id = standardize_id(row['Control Reference'])\n",
    "    cisco_text = row['Control Wording']\n",
    "    \n",
    "    # Get Spanish ENS mappings from three columns (BASIC, Medium, High)\n",
    "    spanish_ids = []\n",
    "    for col in ['Spanish ENS BASIC Control', 'Spanish ENS Medium Control', 'Spanish ENS High Control']:\n",
    "        spanish_ids.extend(parse_control_ids(row.get(col, '')))\n",
    "    \n",
    "    if spanish_ids:\n",
    "        pairs = create_pairs(cisco_id, cisco_text, spanish_ids, spanish_ens_dict)\n",
    "        training_pairs.extend(pairs)\n",
    "\n",
    "print(f\"   Added {len([p for p in training_pairs if p['source_id'].startswith('CCF')])} pairs\")\n",
    "\n",
    "# 2. NewEucsRequirements â†” Cisco\n",
    "print(\"2. Processing NewEucsRequirements â†” Cisco...\")\n",
    "initial_count = len(training_pairs)\n",
    "for _, row in cisco_df.iterrows():\n",
    "    cisco_id = standardize_id(row['Control Reference'])\n",
    "    cisco_text = row['Control Wording']\n",
    "    \n",
    "    # Get EUCS mappings from three columns (Basic, Substantial, High)\n",
    "    eucs_ids = []\n",
    "    for col in ['EUCS Basic Control', 'EUCS Substantial Control', 'EUCS High Control']:\n",
    "        eucs_ids.extend(parse_control_ids(row.get(col, '')))\n",
    "    \n",
    "    if eucs_ids:\n",
    "        pairs = create_pairs(cisco_id, cisco_text, eucs_ids, new_eucs_dict)\n",
    "        training_pairs.extend(pairs)\n",
    "\n",
    "print(f\"   Added {len(training_pairs) - initial_count} pairs\")\n",
    "\n",
    "# 3. Secnumcloud â†” Cisco\n",
    "print(\"3. Processing Secnumcloud â†” Cisco...\")\n",
    "initial_count = len(training_pairs)\n",
    "for _, row in cisco_df.iterrows():\n",
    "    cisco_id = standardize_id(row['Control Reference'])\n",
    "    cisco_text = row['Control Wording']\n",
    "    \n",
    "    secnum_ids = parse_control_ids(row.get('SecNumCloud Control', ''))\n",
    "    \n",
    "    if secnum_ids:\n",
    "        pairs = create_pairs(cisco_id, cisco_text, secnum_ids, secnumcloud_dict)\n",
    "        training_pairs.extend(pairs)\n",
    "\n",
    "print(f\"   Added {len(training_pairs) - initial_count} pairs\")\n",
    "\n",
    "# 4. BSI-C5 â†” Cisco\n",
    "print(\"4. Processing BSI-C5 â†” Cisco...\")\n",
    "initial_count = len(training_pairs)\n",
    "for _, row in cisco_df.iterrows():\n",
    "    cisco_id = standardize_id(row['Control Reference'])\n",
    "    cisco_text = row['Control Wording']\n",
    "    \n",
    "    bsi_ids = parse_control_ids(row.get('BSI C5', ''))\n",
    "    \n",
    "    if bsi_ids:\n",
    "        pairs = create_pairs(cisco_id, cisco_text, bsi_ids, bsi_c5_dict)\n",
    "        training_pairs.extend(pairs)\n",
    "\n",
    "print(f\"   Added {len(training_pairs) - initial_count} pairs\")\n",
    "\n",
    "# 5. BSI-C5 â†” fabasoftMetrics\n",
    "print(\"5. Processing BSI-C5 â†” fabasoftMetrics...\")\n",
    "initial_count = len(training_pairs)\n",
    "for _, row in fabasoft_df.iterrows():\n",
    "    metric_id = row['ID']\n",
    "    if pd.isna(metric_id):\n",
    "        continue\n",
    "        \n",
    "    metric_desc = row['Description']\n",
    "    \n",
    "    # Parse BSI C5 control IDs from \"Possible Control ID Scheme\" column\n",
    "    control_scheme = row.get('Possible Control ID\\nScheme', '')\n",
    "    bsi_ids = parse_control_ids(control_scheme)\n",
    "    \n",
    "    if bsi_ids:\n",
    "        pairs = create_pairs(metric_id, metric_desc, bsi_ids, bsi_c5_dict)\n",
    "        training_pairs.extend(pairs)\n",
    "\n",
    "print(f\"   Added {len(training_pairs) - initial_count} pairs\")\n",
    "\n",
    "# 6. BSI-C5 â†” NewEucsRequirements (only for IDs NOT in OldEucsRequirements)\n",
    "print(\"6. Processing BSI-C5 â†” NewEucsRequirements (excluding old IDs)...\")\n",
    "initial_count = len(training_pairs)\n",
    "for eucs_id, bsi_ids in new_eucs_to_bsi.items():\n",
    "    # Only include if this EUCS ID is NOT in old requirements\n",
    "    if eucs_id not in old_eucs_ids:\n",
    "        eucs_text = new_eucs_dict.get(eucs_id, '')\n",
    "        if eucs_text:\n",
    "            pairs = create_pairs(eucs_id, eucs_text, bsi_ids, bsi_c5_dict)\n",
    "            training_pairs.extend(pairs)\n",
    "\n",
    "print(f\"   Added {len(training_pairs) - initial_count} pairs\")\n",
    "\n",
    "# 7. fabasoftMetrics â†” NewEucsRequirements\n",
    "print(\"7. Processing fabasoftMetrics â†” NewEucsRequirements...\")\n",
    "initial_count = len(training_pairs)\n",
    "for _, row in fabasoft_df.iterrows():\n",
    "    metric_id = row['ID']\n",
    "    if pd.isna(metric_id):\n",
    "        continue\n",
    "        \n",
    "    metric_desc = row['Description']\n",
    "    \n",
    "    # Parse EUCS control IDs from \"Possible Control ID Scheme\" column\n",
    "    control_scheme = row.get('Possible Control ID\\nScheme', '')\n",
    "    # Look for EUCS pattern (e.g., \"BSI C5 OPS-22\" or just \"OPS-22\")\n",
    "    eucs_ids = []\n",
    "    for line in control_scheme.split('\\n'):\n",
    "        # Extract IDs that match EUCS pattern\n",
    "        ids = parse_control_ids(line)\n",
    "        for id_str in ids:\n",
    "            if id_str in new_eucs_dict:\n",
    "                eucs_ids.append(id_str)\n",
    "    \n",
    "    if eucs_ids:\n",
    "        pairs = create_pairs(metric_id, metric_desc, eucs_ids, new_eucs_dict)\n",
    "        training_pairs.extend(pairs)\n",
    "\n",
    "print(f\"   Added {len(training_pairs) - initial_count} pairs\")\n",
    "\n",
    "# ============================================================================\n",
    "# GENERATE TEST DATASET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING TEST DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_pairs = []\n",
    "\n",
    "# 1. BSI-C5 â†” OldEucsRequirements (all of them)\n",
    "print(\"\\n1. Processing BSI-C5 â†” OldEucsRequirements...\")\n",
    "# We need to find BSI-C5 to Old EUCS mappings\n",
    "# These come from the OldEucsRequirements associations in NewEucsRequirements\n",
    "for eucs_id in old_eucs_ids:\n",
    "    if eucs_id in new_eucs_to_bsi:\n",
    "        eucs_text = old_eucs_dict.get(eucs_id, '')\n",
    "        bsi_ids = new_eucs_to_bsi[eucs_id]\n",
    "        \n",
    "        if eucs_text:\n",
    "            pairs = create_pairs(eucs_id, eucs_text, bsi_ids, bsi_c5_dict)\n",
    "            test_pairs.extend(pairs)\n",
    "\n",
    "print(f\"   Added {len(test_pairs)} pairs\")\n",
    "\n",
    "# 2. medinaMetrics â†” OldEucsRequirements (all of them)\n",
    "print(\"2. Processing medinaMetrics â†” OldEucsRequirements...\")\n",
    "initial_count = len(test_pairs)\n",
    "for _, row in medina_df.iterrows():\n",
    "    metric_id = str(row['ID'])\n",
    "    metric_desc = row['description']\n",
    "    control_id = standardize_id(row['controlId'])\n",
    "    \n",
    "    if control_id in old_eucs_dict:\n",
    "        control_text = old_eucs_dict[control_id]\n",
    "        test_pairs.append({\n",
    "            'source_id': metric_id,\n",
    "            'source_text': metric_desc,\n",
    "            'target_id': control_id,\n",
    "            'target_text': control_text,\n",
    "            'label': 1\n",
    "        })\n",
    "\n",
    "print(f\"   Added {len(test_pairs) - initial_count} pairs\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING DATASETS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Convert to DataFrames\n",
    "train_df = pd.DataFrame(training_pairs)\n",
    "test_df = pd.DataFrame(test_pairs)\n",
    "\n",
    "# Remove duplicates\n",
    "train_df = train_df.drop_duplicates(subset=['source_id', 'target_id'])\n",
    "test_df = test_df.drop_duplicates(subset=['source_id', 'target_id'])\n",
    "\n",
    "# Save to CSV\n",
    "train_df.to_csv(OUTPUT['train'], index=False, encoding='utf-8')\n",
    "test_df.to_csv(OUTPUT['test'], index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\nâœ“ Training dataset saved: {OUTPUT['train']}\")\n",
    "print(f\"  Total pairs: {len(train_df)}\")\n",
    "print(f\"  Unique source IDs: {train_df['source_id'].nunique()}\")\n",
    "print(f\"  Unique target IDs: {train_df['target_id'].nunique()}\")\n",
    "\n",
    "print(f\"\\nâœ“ Test dataset saved: {OUTPUT['test']}\")\n",
    "print(f\"  Total pairs: {len(test_df)}\")\n",
    "print(f\"  Unique source IDs: {test_df['source_id'].nunique()}\")\n",
    "print(f\"  Unique target IDs: {test_df['target_id'].nunique()}\")\n",
    "\n",
    "# Display samples\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING DATASET SAMPLES\")\n",
    "print(\"=\"*70)\n",
    "print(train_df.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST DATASET SAMPLES\")\n",
    "print(\"=\"*70)\n",
    "print(test_df.head(10))\n",
    "\n",
    "print(\"\\nâœ… Dataset generation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e8a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
