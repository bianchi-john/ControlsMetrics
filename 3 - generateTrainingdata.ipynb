{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "591027f2",
   "metadata": {},
   "source": [
    "# Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f96c684b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ CARICAMENTO DATI\n",
      "============================================================\n",
      "ðŸ“‚ Caricamento Cisco.csv...\n",
      "ðŸ“‚ Caricamento SpanishENS.csv...\n",
      "ðŸ“‚ Caricamento SecNumCloud...\n",
      "ðŸ“‚ Caricamento EUCS MEDINA...\n",
      "ðŸ“‚ Caricamento Fabasoft Metrics...\n",
      "\n",
      "âœ… Tutti i file caricati con successo!\n",
      "\n",
      "\n",
      "ðŸ”— PROCESSING CISCO MAPPINGS\n",
      "============================================================\n",
      "âœ“ Cisco processato: 181 righe generate\n",
      "\n",
      "ðŸ”— PROCESSING EUCS MEDINA MAPPINGS\n",
      "============================================================\n",
      "âœ“ EUCS MEDINA processato: 78 righe generate\n",
      "\n",
      "ðŸ”— PROCESSING FABASOFT METRICS MAPPINGS\n",
      "============================================================\n",
      "âœ“ Fabasoft processato: 11 righe generate\n",
      "\n",
      "ðŸ“Š CREAZIONE TRAINING DATAFRAME\n",
      "============================================================\n",
      "âœ“ Training set creato: 278 righe\n",
      "\n",
      "ðŸ” VALIDAZIONE MAPPINGS\n",
      "============================================================\n",
      "\n",
      "1. Controllo Aggregazione SecNumCloud (Top 5 righe):\n",
      "\n",
      "   Source: [Cisco] CCF 1\n",
      "   Target ID Composite: 18.2.1.a | 18.3.a | 18.4.a\n",
      "   Target Text Start: The service provider must document and implement an audit program over three years defining the peri...\n",
      "\n",
      "   Source: [Cisco] CCF 2\n",
      "   Target ID Composite: 12.1.a\n",
      "   Target Text Start: The service provider must document the operating procedures, keep them up to date and make them acce...\n",
      "\n",
      "   Source: [Cisco] CCF 4\n",
      "   Target ID Composite: 18.2.1.a\n",
      "   Target Text Start: The service provider must document and implement an audit program over three years defining the peri...\n",
      "\n",
      "   Source: [Cisco] CCF 8\n",
      "   Target ID Composite: 18.1.a | 18.1.c | 18.1.e\n",
      "   Target Text Start: The service provider must identify the legal, regulatory and contractual requirements in force appli...\n",
      "\n",
      "   Source: [Cisco] CCF 10\n",
      "   Target ID Composite: 11.2.1.c | 11.2.2.c | 17.1.a | 17.1.b | 17.2.a | 17.3.a\n",
      "   Target Text Start: The service provider must define and document derogatory physical access measures in an emergency. T...\n",
      "\n",
      "ðŸ’¾ Training set salvato in: TrainAndTestData/trainData/training_set_control_mappings.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Set\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ControlMappingTrainingSetGenerator:\n",
    "    \"\"\"\n",
    "    Genera un training set unificato.\n",
    "    \n",
    "    MODIFICHE ATTUALI:\n",
    "    - Aggregazione SecNumCloud: Se un controllo EUCS mappa su una sezione (es. 6.1),\n",
    "      tutti i sottocontrolli (6.1.a, 6.1.b) vengono concatenati in un UNICO target.\n",
    "    - Utilizzo Description_EN per SecNumCloud.\n",
    "    - Esclusione BSI C5.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_path: str = \"./Schemes\"):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.data = {}\n",
    "        self.training_rows = []\n",
    "        \n",
    "    def clean_control_id(self, control_id: str) -> str:\n",
    "        \"\"\"Pulisce e normalizza gli ID dei controlli\"\"\"\n",
    "        if pd.isna(control_id) or control_id == '':\n",
    "            return ''\n",
    "        \n",
    "        control_id = str(control_id).strip()\n",
    "        control_id = re.sub(r'^(EUCS\\s+|ISO\\s+)', '', control_id, flags=re.IGNORECASE)\n",
    "        return control_id\n",
    "    \n",
    "    def parse_control_list(self, control_string: str) -> List[str]:\n",
    "        \"\"\"Parsifica stringhe con multipli ID\"\"\"\n",
    "        if pd.isna(control_string) or control_string == '':\n",
    "            return []\n",
    "        \n",
    "        controls = re.split(r'[,\\n]+', str(control_string))\n",
    "        cleaned = []\n",
    "        for ctrl in controls:\n",
    "            ctrl = ctrl.strip()\n",
    "            if ctrl:\n",
    "                cleaned.append(self.clean_control_id(ctrl))\n",
    "        return cleaned\n",
    "\n",
    "    def find_secnumcloud_matches(self, source_ref: str, lookup_dict: Dict) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Trova tutti i controlli SecNumCloud che corrispondono (esatto o per prefisso).\n",
    "        Es: '6.1' -> ['6.1.a', '6.1.b']\n",
    "        \"\"\"\n",
    "        matches = []\n",
    "        source_ref = self.clean_control_id(source_ref)\n",
    "        if not source_ref:\n",
    "            return matches\n",
    "\n",
    "        # 1. Match Esatto\n",
    "        if source_ref in lookup_dict:\n",
    "            matches.append(lookup_dict[source_ref])\n",
    "            return matches\n",
    "\n",
    "        # 2. Match Gerarchico (Prefix)\n",
    "        prefix = source_ref + \".\"\n",
    "        matching_keys = [k for k in lookup_dict.keys() if k.startswith(prefix)]\n",
    "        \n",
    "        # Ordina per mantenere coerenza (es: 6.1.a prima di 6.1.b)\n",
    "        matching_keys.sort()\n",
    "        \n",
    "        for key in matching_keys:\n",
    "            matches.append(lookup_dict[key])\n",
    "            \n",
    "        return matches\n",
    "    \n",
    "    def load_cisco(self) -> pd.DataFrame:\n",
    "        print(\"ðŸ“‚ Caricamento Cisco.csv...\")\n",
    "        df = pd.read_csv(self.base_path / \"Cisco.csv\")\n",
    "        return df\n",
    "    \n",
    "    def load_spanish_ens(self) -> pd.DataFrame:\n",
    "        print(\"ðŸ“‚ Caricamento SpanishENS.csv...\")\n",
    "        df = pd.read_csv(self.base_path / \"SpanishENS.csv\")\n",
    "        return df\n",
    "    \n",
    "    def load_secnumcloud(self) -> pd.DataFrame:\n",
    "        print(\"ðŸ“‚ Caricamento SecNumCloud...\")\n",
    "        df = pd.read_csv(self.base_path / \"secnumcloud_controlsParsedAndTranslatedEnglish.csv\")\n",
    "        return df\n",
    "    \n",
    "    def load_eucs_medina(self) -> pd.DataFrame:\n",
    "        print(\"ðŸ“‚ Caricamento EUCS MEDINA...\")\n",
    "        df = pd.read_csv(self.base_path / \"NewEucsRequirements.csv\")\n",
    "        return df\n",
    "    \n",
    "    def load_fabasoft_metrics(self) -> pd.DataFrame:\n",
    "        print(\"ðŸ“‚ Caricamento Fabasoft Metrics...\")\n",
    "        df = pd.read_csv(self.base_path / \"fabasoftMetrics.csv\")\n",
    "        return df\n",
    "    \n",
    "    def load_all_data(self):\n",
    "        print(\"\\nðŸ”„ CARICAMENTO DATI\\n\" + \"=\"*60)\n",
    "        self.data['cisco'] = self.load_cisco()\n",
    "        self.data['spanish_ens'] = self.load_spanish_ens()\n",
    "        self.data['secnumcloud'] = self.load_secnumcloud()\n",
    "        self.data['eucs_medina'] = self.load_eucs_medina()\n",
    "        self.data['fabasoft'] = self.load_fabasoft_metrics()\n",
    "        print(\"\\nâœ… Tutti i file caricati con successo!\\n\")\n",
    "    \n",
    "    def create_lookup_dict(self, df: pd.DataFrame, id_col: str, text_cols: List[str], \n",
    "                           scheme_name: str) -> Dict[str, Dict]:\n",
    "        lookup = {}\n",
    "        for _, row in df.iterrows():\n",
    "            control_id = self.clean_control_id(row[id_col])\n",
    "            if not control_id:\n",
    "                continue\n",
    "            \n",
    "            text_parts = []\n",
    "            for col in text_cols:\n",
    "                if col in df.columns and pd.notna(row[col]):\n",
    "                    text_parts.append(str(row[col]))\n",
    "            \n",
    "            text = ' '.join(text_parts).strip()\n",
    "            \n",
    "            lookup[control_id] = {\n",
    "                'id': control_id,\n",
    "                'text': text,\n",
    "                'scheme': scheme_name,\n",
    "                'original_id': row[id_col]\n",
    "            }\n",
    "        return lookup\n",
    "    \n",
    "    def process_cisco_mappings(self):\n",
    "        print(\"\\nðŸ”— PROCESSING CISCO MAPPINGS\\n\" + \"=\"*60)\n",
    "        cisco_df = self.data['cisco']\n",
    "        \n",
    "        spanish_lookup = self.create_lookup_dict(self.data['spanish_ens'], 'Control ID', ['Description'], 'SpanishENS')\n",
    "        secnum_lookup = self.create_lookup_dict(self.data['secnumcloud'], 'ID', ['Description_EN'], 'SecNumCloud')\n",
    "        eucs_lookup = self.create_lookup_dict(self.data['eucs_medina'], 'Code', ['EUCS Control (2022)', 'EUCS Text'], 'EUCS')\n",
    "        \n",
    "        count = 0\n",
    "        for idx, row in cisco_df.iterrows():\n",
    "            source_id = row['Control Reference']\n",
    "            source_text = f\"{row['Control Title']} - {row['Control Wording']}\"\n",
    "            mapped_controls = []\n",
    "            \n",
    "            # Spanish ENS (Standard mapping)\n",
    "            for col in ['Spanish ENS BASIC Control', 'Spanish ENS Medium Control', 'Spanish ENS High Control']:\n",
    "                if col in cisco_df.columns and pd.notna(row[col]):\n",
    "                    for ctrl_id in self.parse_control_list(row[col]):\n",
    "                        if ctrl_id in spanish_lookup:\n",
    "                            mapped_controls.append(spanish_lookup[ctrl_id])\n",
    "            \n",
    "            # EUCS (Standard mapping)\n",
    "            if 'EUCS Basic Control' in cisco_df.columns and pd.notna(row['EUCS Basic Control']):\n",
    "                for ctrl_id in self.parse_control_list(row['EUCS Basic Control']):\n",
    "                    if ctrl_id in eucs_lookup:\n",
    "                        mapped_controls.append(eucs_lookup[ctrl_id])\n",
    "            \n",
    "            # SecNumCloud (AGGREGATO)\n",
    "            if 'SecNumCloud Control' in cisco_df.columns and pd.notna(row['SecNumCloud Control']):\n",
    "                all_secnum_matches = []\n",
    "                control_ids = self.parse_control_list(row['SecNumCloud Control'])\n",
    "                \n",
    "                # Raccogli TUTTI i match\n",
    "                for ctrl_id in control_ids:\n",
    "                    found = self.find_secnumcloud_matches(ctrl_id, secnum_lookup)\n",
    "                    all_secnum_matches.extend(found)\n",
    "                \n",
    "                # Se abbiamo trovato match, aggreghiamoli in UN solo oggetto target\n",
    "                if all_secnum_matches:\n",
    "                    # Rimuovi duplicati basati su ID\n",
    "                    unique_matches = {m['id']: m for m in all_secnum_matches}.values()\n",
    "                    \n",
    "                    # Concatena ID e Testi\n",
    "                    combined_id = \" | \".join([m['id'] for m in unique_matches])\n",
    "                    combined_text = \" \".join([m['text'] for m in unique_matches])\n",
    "                    \n",
    "                    mapped_controls.append({\n",
    "                        'id': combined_id,\n",
    "                        'text': combined_text,\n",
    "                        'scheme': 'SecNumCloud',\n",
    "                        'original_id': row['SecNumCloud Control']\n",
    "                    })\n",
    "\n",
    "            if mapped_controls:\n",
    "                self.training_rows.append({\n",
    "                    'source_scheme': 'Cisco',\n",
    "                    'source_id': source_id,\n",
    "                    'source_text': source_text,\n",
    "                    'mapped_controls': mapped_controls\n",
    "                })\n",
    "                count += 1\n",
    "                \n",
    "        print(f\"âœ“ Cisco processato: {count} righe generate\")\n",
    "\n",
    "    def process_eucs_medina_mappings(self):\n",
    "        print(\"\\nðŸ”— PROCESSING EUCS MEDINA MAPPINGS\\n\" + \"=\"*60)\n",
    "        eucs_df = self.data['eucs_medina']\n",
    "        \n",
    "        secnum_lookup = self.create_lookup_dict(self.data['secnumcloud'], 'ID', ['Description_EN'], 'SecNumCloud')\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        for idx, row in eucs_df.iterrows():\n",
    "            source_id = row['Code'] if pd.notna(row['Code']) else f\"EUCS-{idx}\"\n",
    "            source_text = f\"{row['EUCS Control (2022)']} - {row['EUCS Text']}\"\n",
    "            \n",
    "            mapped_controls = []\n",
    "            \n",
    "            # Mapping verso SecNumCloud con AGGREGAZIONE\n",
    "            if 'SecNumCloud FRANCE ' in eucs_df.columns and pd.notna(row['SecNumCloud FRANCE ']):\n",
    "                all_secnum_matches = []\n",
    "                control_ids = self.parse_control_list(row['SecNumCloud FRANCE '])\n",
    "                \n",
    "                # 1. Trova tutti i sottocontrolli (es. 6.1 -> 6.1.a, 6.1.b...)\n",
    "                for ctrl_id in control_ids:\n",
    "                    found = self.find_secnumcloud_matches(ctrl_id, secnum_lookup)\n",
    "                    all_secnum_matches.extend(found)\n",
    "                \n",
    "                # 2. Aggrega in una singola entry\n",
    "                if all_secnum_matches:\n",
    "                    # Deduping (caso raro ma possibile)\n",
    "                    unique_matches = {m['id']: m for m in all_secnum_matches}.values()\n",
    "                    \n",
    "                    # Concatena gli ID (per riferimento) e i Testi (per embedding)\n",
    "                    # Esempio ID: \"6.1.a | 6.1.b\"\n",
    "                    combined_id = \" | \".join([m['id'] for m in unique_matches])\n",
    "                    combined_text = \" \".join([m['text'] for m in unique_matches])\n",
    "                    \n",
    "                    mapped_controls.append({\n",
    "                        'id': combined_id,\n",
    "                        'text': combined_text,\n",
    "                        'scheme': 'SecNumCloud',\n",
    "                        'original_id': row['SecNumCloud FRANCE ']\n",
    "                    })\n",
    "\n",
    "            if mapped_controls:\n",
    "                self.training_rows.append({\n",
    "                    'source_scheme': 'EUCS',\n",
    "                    'source_id': source_id,\n",
    "                    'source_text': source_text,\n",
    "                    'mapped_controls': mapped_controls\n",
    "                })\n",
    "                count += 1\n",
    "        \n",
    "        print(f\"âœ“ EUCS MEDINA processato: {count} righe generate\")\n",
    "    \n",
    "    def process_fabasoft_mappings(self):\n",
    "        print(\"\\nðŸ”— PROCESSING FABASOFT METRICS MAPPINGS\\n\" + \"=\"*60)\n",
    "        fabasoft_df = self.data['fabasoft']\n",
    "        eucs_lookup = self.create_lookup_dict(self.data['eucs_medina'], 'Code', ['EUCS Control (2022)', 'EUCS Text'], 'EUCS')\n",
    "        \n",
    "        count = 0\n",
    "        for idx, row in fabasoft_df.iterrows():\n",
    "            source_id = row['ID'] if pd.notna(row['ID']) else f\"Metric-{idx}\"\n",
    "            source_text = f\"{row['Name']} - {row['Description']}\" if pd.notna(row['Description']) else row['Name']\n",
    "            \n",
    "            mapped_controls = []\n",
    "            \n",
    "            if 'Possible Control ID\\nScheme' in fabasoft_df.columns and pd.notna(row['Possible Control ID\\nScheme']):\n",
    "                lines = str(row['Possible Control ID\\nScheme']).split('\\n')\n",
    "                for line in lines:\n",
    "                    line = line.strip()\n",
    "                    if 'EUCS' in line:\n",
    "                        match = re.search(r'EUCS\\s+([A-Z]+-\\d+)', line)\n",
    "                        if match:\n",
    "                            ctrl_id = self.clean_control_id(match.group(1))\n",
    "                            if ctrl_id in eucs_lookup:\n",
    "                                mapped_controls.append(eucs_lookup[ctrl_id])\n",
    "            \n",
    "            if mapped_controls:\n",
    "                self.training_rows.append({\n",
    "                    'source_scheme': 'Fabasoft',\n",
    "                    'source_id': source_id,\n",
    "                    'source_text': source_text,\n",
    "                    'mapped_controls': mapped_controls\n",
    "                })\n",
    "                count += 1\n",
    "                \n",
    "        print(f\"âœ“ Fabasoft processato: {count} righe generate\")\n",
    "    \n",
    "    def create_training_dataframe(self) -> pd.DataFrame:\n",
    "        print(\"\\nðŸ“Š CREAZIONE TRAINING DATAFRAME\\n\" + \"=\"*60)\n",
    "        records = []\n",
    "        for row in self.training_rows:\n",
    "            source_scheme = row['source_scheme']\n",
    "            source_id = row['source_id']\n",
    "            source_text = row['source_text']\n",
    "            \n",
    "            for mapped in row['mapped_controls']:\n",
    "                records.append({\n",
    "                    'source_scheme': source_scheme,\n",
    "                    'source_id': source_id,\n",
    "                    'source_text': source_text,\n",
    "                    'target_scheme': mapped['scheme'],\n",
    "                    'target_id': mapped['id'], # Qui ora avremo ID multipli es \"6.1.a | 6.1.b\"\n",
    "                    'target_text': mapped['text'], # E testo concatenato\n",
    "                    'original_target_id': mapped['original_id']\n",
    "                })\n",
    "        \n",
    "        df = pd.DataFrame(records)\n",
    "        print(f\"âœ“ Training set creato: {len(df)} righe\")\n",
    "        return df\n",
    "    \n",
    "    def validate_mappings(self, df: pd.DataFrame):\n",
    "        print(\"\\nðŸ” VALIDAZIONE MAPPINGS\\n\" + \"=\"*60)\n",
    "        if df.empty:\n",
    "            print(\"  âš ï¸ DataFrame vuoto.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n1. Controllo Aggregazione SecNumCloud (Top 5 righe):\")\n",
    "        # Filtra solo le righe dove il target Ã¨ SecNumCloud\n",
    "        sn_rows = df[df['target_scheme'] == 'SecNumCloud']\n",
    "        if not sn_rows.empty:\n",
    "            for _, row in sn_rows.head(5).iterrows():\n",
    "                print(f\"\\n   Source: [{row['source_scheme']}] {row['source_id']}\")\n",
    "                print(f\"   Target ID Composite: {row['target_id']}\")\n",
    "                # Mostra un'anteprima del testo per verificare la concatenazione\n",
    "                preview_text = row['target_text'][:100] + \"...\" if len(row['target_text']) > 100 else row['target_text']\n",
    "                print(f\"   Target Text Start: {preview_text}\")\n",
    "        else:\n",
    "            print(\"   Nessun mapping verso SecNumCloud trovato.\")\n",
    "\n",
    "    def save_training_set(self, df: pd.DataFrame, output_path: str = \"training_set_control_mappings.csv\"):\n",
    "        df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "        print(f\"\\nðŸ’¾ Training set salvato in: {output_path}\")\n",
    "\n",
    "    def generate(self, output_path: str = \"training_set_control_mappings.csv\"):\n",
    "        self.load_all_data()\n",
    "        self.process_cisco_mappings()\n",
    "        self.process_eucs_medina_mappings()\n",
    "        self.process_fabasoft_mappings()\n",
    "        df = self.create_training_dataframe()\n",
    "        self.validate_mappings(df)\n",
    "        self.save_training_set(df, output_path)\n",
    "        return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generator = ControlMappingTrainingSetGenerator(base_path=\"./Schemes\")\n",
    "    training_df = generator.generate(output_path=\"TrainAndTestData/trainData/training_set_control_mappings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e8a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
