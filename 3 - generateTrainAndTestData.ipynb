{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "591027f2",
   "metadata": {},
   "source": [
    "# Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e2e8a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data files...\n",
      "✓ Loaded Cisco.csv: 713 rows\n",
      "✓ Loaded SpanishENS.csv: 204 controls\n",
      "✓ Loaded Secnumcloud.csv: 261 controls\n",
      "✓ Loaded BSI-C5.json: 222 controls\n",
      "✓ Loaded OldEucsRequirements.csv: 70 controls\n",
      "✓ Loaded NewEucsRequirements.csv: 522 controls\n",
      "  - BSI-C5 mappings: 492\n",
      "  - SecNumCloud mappings: 366\n",
      "✓ Loaded medinaMetrics.csv: 183 metrics\n",
      "✓ Loaded fabasoftMetrics.csv: 57 metrics\n",
      "\n",
      "======================================================================\n",
      "GENERATING TRAINING DATASET\n",
      "======================================================================\n",
      "\n",
      "1. Processing SpanishENS ↔ Cisco...\n",
      "   Added 9 pairs\n",
      "2. Processing NewEucsRequirements ↔ Cisco...\n",
      "   Added 1277 pairs\n",
      "3. Processing Secnumcloud ↔ Cisco...\n",
      "   Added 568 pairs\n",
      "4. Processing BSI-C5 ↔ Cisco...\n",
      "   Added 554 pairs\n",
      "5. Processing BSI-C5 ↔ fabasoftMetrics...\n",
      "   Added 27 pairs\n",
      "6. Processing BSI-C5 ↔ NewEucsRequirements (excluding old IDs)...\n",
      "   Added 564 pairs\n",
      "7. Processing fabasoftMetrics ↔ NewEucsRequirements...\n",
      "   Added 0 pairs\n",
      "\n",
      "======================================================================\n",
      "GENERATING TEST DATASET\n",
      "======================================================================\n",
      "\n",
      "1. Processing BSI-C5 ↔ OldEucsRequirements...\n",
      "   Added 0 pairs\n",
      "2. Processing medinaMetrics ↔ OldEucsRequirements...\n",
      "   Added 179 pairs\n",
      "\n",
      "======================================================================\n",
      "SAVING DATASETS\n",
      "======================================================================\n",
      "\n",
      "✓ Training dataset saved: TrainAndTestData/training_dataset.csv\n",
      "  Total pairs: 2993\n",
      "  Unique source IDs: 756\n",
      "  Unique target IDs: 875\n",
      "\n",
      "✓ Test dataset saved: TrainAndTestData/test_dataset.csv\n",
      "  Total pairs: 179\n",
      "  Unique source IDs: 166\n",
      "  Unique target IDs: 70\n",
      "\n",
      "======================================================================\n",
      "TRAINING DATASET SAMPLES\n",
      "======================================================================\n",
      "  source_id                                        source_text  target_id  \\\n",
      "0     CCF 1  Independent Control self-assessments are perfo...    op.pl.5   \n",
      "1     CCF 9  When applicable, [The Organization], products ...    op.pl.5   \n",
      "2    CCF 63  Policies and instructions with technical and o...  mp.info.2   \n",
      "3    CCF 66  A formal inventory of production system assets...  mp.info.2   \n",
      "4    CCF 70  Systems data classification criteria are revie...  mp.info.2   \n",
      "5   CCF 111  Management has established defined roles and r...  mp.info.2   \n",
      "6   CCF 114  [The Organization] identifies geographies with...  mp.info.2   \n",
      "7   CCF 118  [The Organization] has an established security...  mp.info.2   \n",
      "8   CCF 126  Information security policies are documented a...  mp.info.2   \n",
      "9     CCF 1  Independent Control self-assessments are perfo...   OIS-02.3   \n",
      "\n",
      "                                         target_text  label  \n",
      "0                                     shall be used.      1  \n",
      "1                                     shall be used.      1  \n",
      "2  must be protected by specific security measure...      1  \n",
      "3  must be protected by specific security measure...      1  \n",
      "4  must be protected by specific security measure...      1  \n",
      "5  must be protected by specific security measure...      1  \n",
      "6  must be protected by specific security measure...      1  \n",
      "7  must be protected by specific security measure...      1  \n",
      "8  must be protected by specific security measure...      1  \n",
      "9  The CSP shall implement the mitigating measure...      1  \n",
      "\n",
      "======================================================================\n",
      "TEST DATASET SAMPLES\n",
      "======================================================================\n",
      "  source_id                                        source_text  target_id  \\\n",
      "0         1  This metric is used to assess if the antimalwa...  OPS-05.3H   \n",
      "1         2  This metric is used to assess if the antimalwa...  OPS-05.3H   \n",
      "2         3  This metric is used to assess if backups are e...  OPS-07.2H   \n",
      "3         3  This metric is used to assess if backups are e...  OPS-09.2H   \n",
      "4         4  This metric is used to assess the configured b...  OPS-07.2H   \n",
      "5         5  This metric is used to assess if Anomaly Detec...  OPS-13.1H   \n",
      "6         6  This metric is used to assess if activity logs...  OPS-13.1H   \n",
      "7         7  This metric is used to assess if Application l...  OPS-13.1H   \n",
      "8         8  This metric is used to assess if Boot logs are...  OPS-13.1H   \n",
      "9         9  This metric is used to assess if OS logs are e...  OPS-13.1H   \n",
      "\n",
      "                                         target_text  label  \n",
      "0  The CSP shall automatically monitor the system...      1  \n",
      "1  The CSP shall automatically monitor the system...      1  \n",
      "2  In order to check the proper application of th...      1  \n",
      "3  When the backup data is transmitted to a remot...      1  \n",
      "4  In order to check the proper application of th...      1  \n",
      "5  The CSP shall store all log data in an integri...      1  \n",
      "6  The CSP shall store all log data in an integri...      1  \n",
      "7  The CSP shall store all log data in an integri...      1  \n",
      "8  The CSP shall store all log data in an integri...      1  \n",
      "9  The CSP shall store all log data in an integri...      1  \n",
      "\n",
      "✅ Dataset generation complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from typing import List, Tuple, Set\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# File paths\n",
    "FILES = {\n",
    "    'cisco': 'Schemes/Cisco.csv',\n",
    "    'spanish_ens': 'Schemes/SpanishENS.csv',\n",
    "    'secnumcloud': 'Schemes/Secnumcloud.csv',\n",
    "    'bsi_c5': 'Schemes/BSI-C5.json',\n",
    "    'old_eucs': 'Schemes/OldEucsRequirements.csv',\n",
    "    'new_eucs': 'Schemes/NewEucsRequirements_with_texts.csv',\n",
    "    'medina_metrics': 'Schemes/medinaMetrics.csv',\n",
    "    'fabasoft_metrics': 'Schemes/fabasoftMetrics.csv'\n",
    "}\n",
    "\n",
    "# Output files\n",
    "OUTPUT = {\n",
    "    'train': 'TrainAndTestData/training_dataset.csv',\n",
    "    'test': 'TrainAndTestData/test_dataset.csv'\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def standardize_id(control_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Standardize control IDs by removing extra whitespace and normalizing format.\n",
    "    Examples:\n",
    "    - \"OPS-05.3H \" -> \"OPS-05.3H\"\n",
    "    - \"OIS-01 \" -> \"OIS-01\"\n",
    "    - \" BSI C5 OPS-22\" -> \"OPS-22\"\n",
    "    \"\"\"\n",
    "    if pd.isna(control_id) or control_id == '':\n",
    "        return ''\n",
    "    \n",
    "    # Convert to string and strip whitespace\n",
    "    control_id = str(control_id).strip()\n",
    "    \n",
    "    # Remove \"BSI C5 \" prefix if present\n",
    "    control_id = re.sub(r'^BSI\\s+C5\\s+', '', control_id, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove extra internal whitespace\n",
    "    control_id = re.sub(r'\\s+', ' ', control_id)\n",
    "    \n",
    "    return control_id\n",
    "\n",
    "def parse_control_ids(value: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parse a string containing multiple control IDs separated by commas or newlines.\n",
    "    Returns a list of standardized IDs.\n",
    "    \"\"\"\n",
    "    if pd.isna(value) or value == '':\n",
    "        return []\n",
    "    \n",
    "    # Split by comma or newline\n",
    "    ids = re.split(r'[,\\n]+', str(value))\n",
    "    \n",
    "    # Standardize each ID and filter out empty strings\n",
    "    standardized = [standardize_id(id_str) for id_str in ids]\n",
    "    return [id_str for id_str in standardized if id_str]\n",
    "\n",
    "def create_pairs(source_id: str, source_text: str, target_ids: List[str], \n",
    "                 target_texts: dict, label: int = 1) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Create training/test pairs from source control to target controls.\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    for target_id in target_ids:\n",
    "        if target_id in target_texts:\n",
    "            pairs.append({\n",
    "                'source_id': source_id,\n",
    "                'source_text': source_text,\n",
    "                'target_id': target_id,\n",
    "                'target_text': target_texts[target_id],\n",
    "                'label': label\n",
    "            })\n",
    "    return pairs\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Loading data files...\")\n",
    "\n",
    "# Load Cisco CSV\n",
    "cisco_df = pd.read_csv(FILES['cisco'], encoding='utf-8')\n",
    "print(f\"✓ Loaded Cisco.csv: {len(cisco_df)} rows\")\n",
    "\n",
    "# Load Spanish ENS\n",
    "spanish_ens_df = pd.read_csv(FILES['spanish_ens'], encoding='utf-8')\n",
    "spanish_ens_dict = dict(zip(\n",
    "    spanish_ens_df['Control ID'].apply(standardize_id),\n",
    "    spanish_ens_df['Description']\n",
    "))\n",
    "print(f\"✓ Loaded SpanishENS.csv: {len(spanish_ens_dict)} controls\")\n",
    "\n",
    "# Load SecNumCloud\n",
    "secnumcloud_df = pd.read_csv(FILES['secnumcloud'], encoding='utf-8')\n",
    "secnumcloud_dict = dict(zip(\n",
    "    secnumcloud_df['ID'].apply(standardize_id),\n",
    "    secnumcloud_df['Description_EN']\n",
    "))\n",
    "print(f\"✓ Loaded Secnumcloud.csv: {len(secnumcloud_dict)} controls\")\n",
    "\n",
    "# Load BSI-C5 JSON\n",
    "with open(FILES['bsi_c5'], 'r', encoding='utf-8') as f:\n",
    "    bsi_c5_data = json.load(f)\n",
    "\n",
    "bsi_c5_dict = {}\n",
    "for control in bsi_c5_data:\n",
    "    code = standardize_id(control.get('code', ''))\n",
    "    if code and code != 'AAA-00':  # Skip generic control\n",
    "        desc = control.get('descriptionTitle', '')\n",
    "        if desc:\n",
    "            bsi_c5_dict[code] = desc\n",
    "print(f\"✓ Loaded BSI-C5.json: {len(bsi_c5_dict)} controls\")\n",
    "\n",
    "# Load Old EUCS Requirements\n",
    "old_eucs_df = pd.read_csv(FILES['old_eucs'], encoding='utf-8')\n",
    "old_eucs_dict = dict(zip(\n",
    "    old_eucs_df['controlId'].apply(standardize_id),\n",
    "    old_eucs_df['description']\n",
    "))\n",
    "old_eucs_ids = set(old_eucs_dict.keys())\n",
    "print(f\"✓ Loaded OldEucsRequirements.csv: {len(old_eucs_dict)} controls\")\n",
    "\n",
    "# Load New EUCS Requirements\n",
    "new_eucs_df = pd.read_csv(FILES['new_eucs'], encoding='utf-8')\n",
    "new_eucs_dict = {}\n",
    "new_eucs_to_bsi = {}\n",
    "new_eucs_to_secnum = {}\n",
    "new_eucs_to_iso27002 = {}\n",
    "new_eucs_to_iso27017 = {}\n",
    "\n",
    "for _, row in new_eucs_df.iterrows():\n",
    "    eucs_id = standardize_id(row['EUCS Ref (Detailed)'])\n",
    "    eucs_text = row['EUCS Text']\n",
    "    \n",
    "    if eucs_id and pd.notna(eucs_text):\n",
    "        new_eucs_dict[eucs_id] = eucs_text\n",
    "        \n",
    "        # Parse mappings\n",
    "        bsi_ids = parse_control_ids(row.get('C5.2020 GERMANY ', ''))\n",
    "        secnum_ids = parse_control_ids(row.get('SecNumCloud FRANCE ', ''))\n",
    "        iso27002_ids = parse_control_ids(row.get('ISO 27002 ', ''))\n",
    "        iso27017_ids = parse_control_ids(row.get('ISO 27017 ', ''))\n",
    "        \n",
    "        if bsi_ids:\n",
    "            new_eucs_to_bsi[eucs_id] = bsi_ids\n",
    "        if secnum_ids:\n",
    "            new_eucs_to_secnum[eucs_id] = secnum_ids\n",
    "        if iso27002_ids:\n",
    "            new_eucs_to_iso27002[eucs_id] = iso27002_ids\n",
    "        if iso27017_ids:\n",
    "            new_eucs_to_iso27017[eucs_id] = iso27017_ids\n",
    "\n",
    "print(f\"✓ Loaded NewEucsRequirements.csv: {len(new_eucs_dict)} controls\")\n",
    "print(f\"  - BSI-C5 mappings: {len(new_eucs_to_bsi)}\")\n",
    "print(f\"  - SecNumCloud mappings: {len(new_eucs_to_secnum)}\")\n",
    "\n",
    "# Load Medina Metrics\n",
    "medina_df = pd.read_csv(FILES['medina_metrics'], encoding='utf-8')\n",
    "medina_dict = {}\n",
    "for _, row in medina_df.iterrows():\n",
    "    metric_id = str(row['ID'])\n",
    "    metric_desc = row['description']\n",
    "    medina_dict[metric_id] = metric_desc\n",
    "print(f\"✓ Loaded medinaMetrics.csv: {len(medina_df)} metrics\")\n",
    "\n",
    "# Load Fabasoft Metrics\n",
    "fabasoft_df = pd.read_csv(FILES['fabasoft_metrics'], encoding='utf-8')\n",
    "fabasoft_dict = {}\n",
    "for _, row in fabasoft_df.iterrows():\n",
    "    metric_id = row['ID']\n",
    "    if pd.notna(metric_id):\n",
    "        metric_desc = row['Description']\n",
    "        fabasoft_dict[metric_id] = metric_desc\n",
    "print(f\"✓ Loaded fabasoftMetrics.csv: {len(fabasoft_dict)} metrics\")\n",
    "\n",
    "# ============================================================================\n",
    "# GENERATE TRAINING DATASET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING TRAINING DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "training_pairs = []\n",
    "\n",
    "# 1. SpanishENS ↔ Cisco\n",
    "print(\"\\n1. Processing SpanishENS ↔ Cisco...\")\n",
    "for _, row in cisco_df.iterrows():\n",
    "    cisco_id = standardize_id(row['Control Reference'])\n",
    "    cisco_text = row['Control Wording']\n",
    "    \n",
    "    # Get Spanish ENS mappings from three columns (BASIC, Medium, High)\n",
    "    spanish_ids = []\n",
    "    for col in ['Spanish ENS BASIC Control', 'Spanish ENS Medium Control', 'Spanish ENS High Control']:\n",
    "        spanish_ids.extend(parse_control_ids(row.get(col, '')))\n",
    "    \n",
    "    if spanish_ids:\n",
    "        pairs = create_pairs(cisco_id, cisco_text, spanish_ids, spanish_ens_dict)\n",
    "        training_pairs.extend(pairs)\n",
    "\n",
    "print(f\"   Added {len([p for p in training_pairs if p['source_id'].startswith('CCF')])} pairs\")\n",
    "\n",
    "# 2. NewEucsRequirements ↔ Cisco\n",
    "print(\"2. Processing NewEucsRequirements ↔ Cisco...\")\n",
    "initial_count = len(training_pairs)\n",
    "for _, row in cisco_df.iterrows():\n",
    "    cisco_id = standardize_id(row['Control Reference'])\n",
    "    cisco_text = row['Control Wording']\n",
    "    \n",
    "    # Get EUCS mappings from three columns (Basic, Substantial, High)\n",
    "    eucs_ids = []\n",
    "    for col in ['EUCS Basic Control', 'EUCS Substantial Control', 'EUCS High Control']:\n",
    "        eucs_ids.extend(parse_control_ids(row.get(col, '')))\n",
    "    \n",
    "    if eucs_ids:\n",
    "        pairs = create_pairs(cisco_id, cisco_text, eucs_ids, new_eucs_dict)\n",
    "        training_pairs.extend(pairs)\n",
    "\n",
    "print(f\"   Added {len(training_pairs) - initial_count} pairs\")\n",
    "\n",
    "# 3. Secnumcloud ↔ Cisco\n",
    "print(\"3. Processing Secnumcloud ↔ Cisco...\")\n",
    "initial_count = len(training_pairs)\n",
    "for _, row in cisco_df.iterrows():\n",
    "    cisco_id = standardize_id(row['Control Reference'])\n",
    "    cisco_text = row['Control Wording']\n",
    "    \n",
    "    secnum_ids = parse_control_ids(row.get('SecNumCloud Control', ''))\n",
    "    \n",
    "    if secnum_ids:\n",
    "        pairs = create_pairs(cisco_id, cisco_text, secnum_ids, secnumcloud_dict)\n",
    "        training_pairs.extend(pairs)\n",
    "\n",
    "print(f\"   Added {len(training_pairs) - initial_count} pairs\")\n",
    "\n",
    "# 4. BSI-C5 ↔ Cisco\n",
    "print(\"4. Processing BSI-C5 ↔ Cisco...\")\n",
    "initial_count = len(training_pairs)\n",
    "for _, row in cisco_df.iterrows():\n",
    "    cisco_id = standardize_id(row['Control Reference'])\n",
    "    cisco_text = row['Control Wording']\n",
    "    \n",
    "    bsi_ids = parse_control_ids(row.get('BSI C5', ''))\n",
    "    \n",
    "    if bsi_ids:\n",
    "        pairs = create_pairs(cisco_id, cisco_text, bsi_ids, bsi_c5_dict)\n",
    "        training_pairs.extend(pairs)\n",
    "\n",
    "print(f\"   Added {len(training_pairs) - initial_count} pairs\")\n",
    "\n",
    "# 5. BSI-C5 ↔ fabasoftMetrics\n",
    "print(\"5. Processing BSI-C5 ↔ fabasoftMetrics...\")\n",
    "initial_count = len(training_pairs)\n",
    "for _, row in fabasoft_df.iterrows():\n",
    "    metric_id = row['ID']\n",
    "    if pd.isna(metric_id):\n",
    "        continue\n",
    "        \n",
    "    metric_desc = row['Description']\n",
    "    \n",
    "    # Parse BSI C5 control IDs from \"Possible Control ID Scheme\" column\n",
    "    control_scheme = row.get('Possible Control ID\\nScheme', '')\n",
    "    bsi_ids = parse_control_ids(control_scheme)\n",
    "    \n",
    "    if bsi_ids:\n",
    "        pairs = create_pairs(metric_id, metric_desc, bsi_ids, bsi_c5_dict)\n",
    "        training_pairs.extend(pairs)\n",
    "\n",
    "print(f\"   Added {len(training_pairs) - initial_count} pairs\")\n",
    "\n",
    "# 6. BSI-C5 ↔ NewEucsRequirements (only for IDs NOT in OldEucsRequirements)\n",
    "print(\"6. Processing BSI-C5 ↔ NewEucsRequirements (excluding old IDs)...\")\n",
    "initial_count = len(training_pairs)\n",
    "for eucs_id, bsi_ids in new_eucs_to_bsi.items():\n",
    "    # Only include if this EUCS ID is NOT in old requirements\n",
    "    if eucs_id not in old_eucs_ids:\n",
    "        eucs_text = new_eucs_dict.get(eucs_id, '')\n",
    "        if eucs_text:\n",
    "            pairs = create_pairs(eucs_id, eucs_text, bsi_ids, bsi_c5_dict)\n",
    "            training_pairs.extend(pairs)\n",
    "\n",
    "print(f\"   Added {len(training_pairs) - initial_count} pairs\")\n",
    "\n",
    "# 7. fabasoftMetrics ↔ NewEucsRequirements\n",
    "print(\"7. Processing fabasoftMetrics ↔ NewEucsRequirements...\")\n",
    "initial_count = len(training_pairs)\n",
    "for _, row in fabasoft_df.iterrows():\n",
    "    metric_id = row['ID']\n",
    "    if pd.isna(metric_id):\n",
    "        continue\n",
    "        \n",
    "    metric_desc = row['Description']\n",
    "    \n",
    "    # Parse EUCS control IDs from \"Possible Control ID Scheme\" column\n",
    "    control_scheme = row.get('Possible Control ID\\nScheme', '')\n",
    "    \n",
    "    # Check if control_scheme is valid (not NaN or empty)\n",
    "    if pd.isna(control_scheme) or control_scheme == '':\n",
    "        continue\n",
    "    \n",
    "    # Look for EUCS pattern (e.g., \"BSI C5 OPS-22\" or just \"OPS-22\")\n",
    "    eucs_ids = []\n",
    "    for line in str(control_scheme).split('\\n'):\n",
    "        # Extract IDs that match EUCS pattern\n",
    "        ids = parse_control_ids(line)\n",
    "        for id_str in ids:\n",
    "            if id_str in new_eucs_dict:\n",
    "                eucs_ids.append(id_str)\n",
    "    \n",
    "    if eucs_ids:\n",
    "        pairs = create_pairs(metric_id, metric_desc, eucs_ids, new_eucs_dict)\n",
    "        training_pairs.extend(pairs)\n",
    "\n",
    "print(f\"   Added {len(training_pairs) - initial_count} pairs\")\n",
    "\n",
    "# ============================================================================\n",
    "# GENERATE TEST DATASET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING TEST DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_pairs = []\n",
    "\n",
    "# 1. BSI-C5 ↔ OldEucsRequirements (all of them)\n",
    "print(\"\\n1. Processing BSI-C5 ↔ OldEucsRequirements...\")\n",
    "# We need to find BSI-C5 to Old EUCS mappings\n",
    "# These come from the OldEucsRequirements associations in NewEucsRequirements\n",
    "for eucs_id in old_eucs_ids:\n",
    "    if eucs_id in new_eucs_to_bsi:\n",
    "        eucs_text = old_eucs_dict.get(eucs_id, '')\n",
    "        bsi_ids = new_eucs_to_bsi[eucs_id]\n",
    "        \n",
    "        if eucs_text:\n",
    "            pairs = create_pairs(eucs_id, eucs_text, bsi_ids, bsi_c5_dict)\n",
    "            test_pairs.extend(pairs)\n",
    "\n",
    "print(f\"   Added {len(test_pairs)} pairs\")\n",
    "\n",
    "# 2. medinaMetrics ↔ OldEucsRequirements (all of them)\n",
    "print(\"2. Processing medinaMetrics ↔ OldEucsRequirements...\")\n",
    "initial_count = len(test_pairs)\n",
    "for _, row in medina_df.iterrows():\n",
    "    metric_id = str(row['ID'])\n",
    "    metric_desc = row['description']\n",
    "    control_id = standardize_id(row['controlId'])\n",
    "    \n",
    "    if control_id in old_eucs_dict:\n",
    "        control_text = old_eucs_dict[control_id]\n",
    "        test_pairs.append({\n",
    "            'source_id': metric_id,\n",
    "            'source_text': metric_desc,\n",
    "            'target_id': control_id,\n",
    "            'target_text': control_text,\n",
    "            'label': 1\n",
    "        })\n",
    "\n",
    "print(f\"   Added {len(test_pairs) - initial_count} pairs\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING DATASETS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Convert to DataFrames\n",
    "train_df = pd.DataFrame(training_pairs)\n",
    "test_df = pd.DataFrame(test_pairs)\n",
    "\n",
    "# Remove duplicates\n",
    "train_df = train_df.drop_duplicates(subset=['source_id', 'target_id'])\n",
    "test_df = test_df.drop_duplicates(subset=['source_id', 'target_id'])\n",
    "\n",
    "# Save to CSV\n",
    "train_df.to_csv(OUTPUT['train'], index=False, encoding='utf-8')\n",
    "test_df.to_csv(OUTPUT['test'], index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\n✓ Training dataset saved: {OUTPUT['train']}\")\n",
    "print(f\"  Total pairs: {len(train_df)}\")\n",
    "print(f\"  Unique source IDs: {train_df['source_id'].nunique()}\")\n",
    "print(f\"  Unique target IDs: {train_df['target_id'].nunique()}\")\n",
    "\n",
    "print(f\"\\n✓ Test dataset saved: {OUTPUT['test']}\")\n",
    "print(f\"  Total pairs: {len(test_df)}\")\n",
    "print(f\"  Unique source IDs: {test_df['source_id'].nunique()}\")\n",
    "print(f\"  Unique target IDs: {test_df['target_id'].nunique()}\")\n",
    "\n",
    "# Display samples\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING DATASET SAMPLES\")\n",
    "print(\"=\"*70)\n",
    "print(train_df.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST DATASET SAMPLES\")\n",
    "print(\"=\"*70)\n",
    "print(test_df.head(10))\n",
    "\n",
    "print(\"\\n✅ Dataset generation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e1c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
