{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "591027f2",
   "metadata": {},
   "source": [
    "# Generate training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e0951c",
   "metadata": {},
   "source": [
    "### CISCO and Spaninsh Ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d8a9d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Caricamento file...\n",
      "   - Cisco loaded: (713, 32) righe\n",
      "   - Spanish ENS loaded: (213, 8) righe\n",
      "\n",
      "2. Indicizzazione e Aggregazione ENS (English)...\n",
      "   - Indicizzati 169 codici ENS univoci con testo in Inglese.\n",
      "\n",
      "3. Generazione coppie di training (Cisco -> ENS)...\n",
      "------------------------------\n",
      "RISULTATO FINALE\n",
      "------------------------------\n",
      "Totale coppie generate: 318\n",
      "Codici mancanti (nel file ENS): 28\n",
      "Esempio mancanti: ['mp.s.1', 'mp.com.9', 'op.cont.1', 'mp.info.6', 'mp.info.5']\n",
      "\n",
      "File salvato come: TrainAndTestData/trainingData/training_data_step1_cisco_ens.csv\n",
      "\n",
      "Anteprima dati:\n",
      "                                         anchor_text  \\\n",
      "0  Control Self-Assessments: Independent Control ...   \n",
      "1  Control Self-Assessments: Independent Control ...   \n",
      "\n",
      "                                         target_text  \n",
      "0  Metrics system. Taking into account the securi...  \n",
      "1  Certified components. Is the Catalog of Inform...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CONFIGURAZIONE\n",
    "# ==============================================================================\n",
    "CISCO_PATH = \"Schemes/Cisco.csv\"         # Assicurati che il percorso sia corretto\n",
    "ENS_PATH = \"Schemes/SpanishENS.csv\"      # Assicurati che il percorso sia corretto\n",
    "OUTPUT_FILE = \"TrainAndTestData/trainingData/training_data_step1_cisco_ens.csv\"\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. CARICAMENTO DATI\n",
    "# ==============================================================================\n",
    "print(\"1. Caricamento file...\")\n",
    "\n",
    "# Caricamento Cisco\n",
    "df_cisco = pd.read_csv(CISCO_PATH)\n",
    "print(f\"   - Cisco loaded: {df_cisco.shape} righe\")\n",
    "\n",
    "# Caricamento Spanish ENS (con separatore punto e virgola)\n",
    "# Usiamo dtype=str per evitare problemi con codici interpretati come numeri\n",
    "df_ens = pd.read_csv(ENS_PATH, sep=';', dtype=str)\n",
    "print(f\"   - Spanish ENS loaded: {df_ens.shape} righe\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. CREAZIONE LOOKUP TABLE (ENS INGLESE AGGREGATO)\n",
    "# ==============================================================================\n",
    "print(\"\\n2. Indicizzazione e Aggregazione ENS (English)...\")\n",
    "\n",
    "ens_lookup = {}\n",
    "\n",
    "# Raggruppiamo per codice perché nel CSV lo stesso codice può apparire più volte\n",
    "# (es. una riga per il titolo, una riga per le domande)\n",
    "grouped_ens = df_ens.groupby('Codice')\n",
    "\n",
    "for code, group in grouped_ens:\n",
    "    # Normalizza la chiave (codice)\n",
    "    if pd.isna(code): continue\n",
    "    clean_code = str(code).strip().lower()\n",
    "    \n",
    "    # Raccogli tutti i testi INGLESI disponibili per questo codice\n",
    "    texts = []\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        # Titolo Inglese\n",
    "        if 'Titolo_EN' in row and not pd.isna(row['Titolo_EN']):\n",
    "            t = str(row['Titolo_EN']).strip()\n",
    "            if t: texts.append(t)\n",
    "            \n",
    "        # Domande Inglese\n",
    "        if 'Domande_EN' in row and not pd.isna(row['Domande_EN']):\n",
    "            q = str(row['Domande_EN']).strip()\n",
    "            # Rimuovi i pipe '|' che separano le domande e sostituisci con spazio\n",
    "            q = q.replace('|', ' ')\n",
    "            if q: texts.append(q)\n",
    "            \n",
    "    # Unisci tutto il testo raccolto per questo controllo\n",
    "    full_text_en = \". \".join(texts)\n",
    "    \n",
    "    # Pulizia finale (spazi doppi, ecc)\n",
    "    full_text_en = re.sub(r'\\s+', ' ', full_text_en).strip()\n",
    "    \n",
    "    if full_text_en:\n",
    "        ens_lookup[clean_code] = full_text_en\n",
    "\n",
    "print(f\"   - Indicizzati {len(ens_lookup)} codici ENS univoci con testo in Inglese.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. MAPPING E GENERAZIONE DATASET\n",
    "# ==============================================================================\n",
    "print(\"\\n3. Generazione coppie di training (Cisco -> ENS)...\")\n",
    "\n",
    "training_data = []\n",
    "stats = {\n",
    "    \"matches\": 0,\n",
    "    \"missing\": set()\n",
    "}\n",
    "\n",
    "# Colonne Cisco dove cercare i riferimenti ENS\n",
    "ens_columns = ['Spanish ENS BASIC Control', 'Spanish ENS Medium Control', 'Spanish ENS High Control']\n",
    "\n",
    "for idx, row in df_cisco.iterrows():\n",
    "    # Anchor (Cisco)\n",
    "    # Combiniamo Titolo e Wording per la massima ricchezza semantica\n",
    "    if pd.isna(row['Control Reference']): continue\n",
    "    \n",
    "    anchor_id = str(row['Control Reference'])\n",
    "    title = str(row['Control Title']) if not pd.isna(row['Control Title']) else \"\"\n",
    "    wording = str(row['Control Wording']) if not pd.isna(row['Control Wording']) else \"\"\n",
    "    \n",
    "    anchor_text = f\"{title}: {wording}\".strip()\n",
    "    \n",
    "    # Target (ENS)\n",
    "    # Cerchiamo i codici nelle 3 colonne\n",
    "    target_codes = []\n",
    "    for col in ens_columns:\n",
    "        if col in row and not pd.isna(row[col]):\n",
    "            # Split per virgola in caso ci siano più controlli in una cella\n",
    "            codes_in_cell = str(row[col]).split(',')\n",
    "            target_codes.extend([c.strip().lower() for c in codes_in_cell])\n",
    "    \n",
    "    # Rimuovi duplicati e itera\n",
    "    unique_targets = set(target_codes)\n",
    "    \n",
    "    for t_code in unique_targets:\n",
    "        if not t_code: continue\n",
    "        \n",
    "        if t_code in ens_lookup:\n",
    "            # MATCH TROVATO\n",
    "            positive_text = ens_lookup[t_code]\n",
    "            \n",
    "            training_data.append({\n",
    "                'anchor_id': anchor_id,\n",
    "                'anchor_text': anchor_text,\n",
    "                'target_id': t_code,\n",
    "                'target_text': positive_text,\n",
    "                'source': 'Cisco',\n",
    "                'target': 'Spanish ENS (EN)'\n",
    "            })\n",
    "            stats[\"matches\"] += 1\n",
    "        else:\n",
    "            stats[\"missing\"].add(t_code)\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. SALVATAGGIO\n",
    "# ==============================================================================\n",
    "df_train = pd.DataFrame(training_data)\n",
    "df_train.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"RISULTATO FINALE\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Totale coppie generate: {len(df_train)}\")\n",
    "print(f\"Codici mancanti (nel file ENS): {len(stats['missing'])}\")\n",
    "if stats['missing']:\n",
    "    print(f\"Esempio mancanti: {list(stats['missing'])[:5]}\")\n",
    "print(f\"\\nFile salvato come: {OUTPUT_FILE}\")\n",
    "\n",
    "# Anteprima\n",
    "print(\"\\nAnteprima dati:\")\n",
    "print(df_train[['anchor_text', 'target_text']].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cce0c1",
   "metadata": {},
   "source": [
    "### CISCO and Spaninsh Ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e03cbb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Caricamento e indicizzazione SecNumCloud...\n",
      "   - SecNumCloud caricato: 287 righe.\n",
      "   - Indicizzati 261 controlli SecNumCloud univoci (EN).\n",
      "\n",
      "2. Generazione coppie di training (Cisco -> SecNumCloud)...\n",
      "   - Cisco caricato: 713 righe.\n",
      "------------------------------\n",
      "RISULTATO STEP 2\n",
      "------------------------------\n",
      "Nuove coppie generate: 567\n",
      "Codici SecNumCloud non trovati: 33\n",
      "Esempio mancanti: ['8.5.b', '9.6.k', '12.5.d']...\n",
      "\n",
      "File salvato: TrainAndTestData/trainingData/training_data_step2_cisco_secNumCloud.csv\n",
      "\n",
      "Anteprima dati:\n",
      "  anchor_id target_id                                        target_text\n",
      "0     CCF 1  18.2.1.a  The service provider must document and impleme...\n",
      "1     CCF 1    18.4.a  The service provider must document and impleme...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CONFIGURAZIONE PERCORSI\n",
    "# ==============================================================================\n",
    "# Percorsi basati sulla tua struttura di cartelle\n",
    "PATH_CISCO = \"Schemes/Cisco.csv\"\n",
    "PATH_SECNUM = \"Schemes/Secnumcloud.csv\"\n",
    "OUTPUT_FILE = \"TrainAndTestData/trainingData/training_data_step2_cisco_secNumCloud.csv\"\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. CARICAMENTO E INDICIZZAZIONE SECNUMCLOUD\n",
    "# ==============================================================================\n",
    "print(\"1. Caricamento e indicizzazione SecNumCloud...\")\n",
    "\n",
    "try:\n",
    "    # Tentativo di lettura standard (virgola)\n",
    "    df_sec = pd.read_csv(PATH_SECNUM)\n",
    "    \n",
    "    # Verifica colonne critiche\n",
    "    if 'ID' not in df_sec.columns or 'Description_EN' not in df_sec.columns:\n",
    "        # Fallback: prova con punto e virgola se la prima lettura non ha parsato le colonne\n",
    "        df_sec = pd.read_csv(PATH_SECNUM, sep=';')\n",
    "\n",
    "    print(f\"   - SecNumCloud caricato: {len(df_sec)} righe.\")\n",
    "except Exception as e:\n",
    "    print(f\"   - ERRORE critico nel caricamento di SecNumCloud: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Creazione dizionario di lookup: ID (lowercase) -> Descrizione Inglese\n",
    "secnum_lookup = {}\n",
    "for _, row in df_sec.iterrows():\n",
    "    if pd.isna(row['ID']): continue\n",
    "    \n",
    "    # Normalizzazione ID (es: \"5.1.A \" -> \"5.1.a\")\n",
    "    clean_id = str(row['ID']).strip().lower()\n",
    "    \n",
    "    # Estrazione testo inglese\n",
    "    if 'Description_EN' in row and not pd.isna(row['Description_EN']):\n",
    "        desc = str(row['Description_EN']).strip()\n",
    "        secnum_lookup[clean_id] = desc\n",
    "\n",
    "print(f\"   - Indicizzati {len(secnum_lookup)} controlli SecNumCloud univoci (EN).\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. MAPPING CISCO -> SECNUMCLOUD\n",
    "# ==============================================================================\n",
    "print(\"\\n2. Generazione coppie di training (Cisco -> SecNumCloud)...\")\n",
    "\n",
    "df_cisco = pd.read_csv(PATH_CISCO)\n",
    "print(f\"   - Cisco caricato: {len(df_cisco)} righe.\")\n",
    "\n",
    "training_data = []\n",
    "stats = {\n",
    "    \"matches\": 0,\n",
    "    \"missing\": set()\n",
    "}\n",
    "\n",
    "# La colonna Cisco che contiene i riferimenti\n",
    "target_col = 'SecNumCloud Control'\n",
    "\n",
    "for idx, row in df_cisco.iterrows():\n",
    "    # Verifica se c'è un mapping\n",
    "    if target_col not in row or pd.isna(row[target_col]):\n",
    "        continue\n",
    "    \n",
    "    # 1. Preparazione Anchor (Cisco)\n",
    "    anchor_id = str(row['Control Reference'])\n",
    "    title = str(row['Control Title']) if not pd.isna(row['Control Title']) else \"\"\n",
    "    wording = str(row['Control Wording']) if not pd.isna(row['Control Wording']) else \"\"\n",
    "    \n",
    "    # Uniamo titolo e wording per dare contesto completo al modello\n",
    "    anchor_text = f\"{title}: {wording}\".strip()\n",
    "    \n",
    "    # 2. Preparazione Target (SecNumCloud IDs)\n",
    "    # Cisco può contenere liste tipo \"5.1.a, 5.2.b\" o usare newline\n",
    "    raw_refs = str(row[target_col]).replace('\\n', ',')\n",
    "    target_ids_list = [t.strip().lower() for t in raw_refs.split(',')]\n",
    "    \n",
    "    # 3. Matching\n",
    "    for t_id in set(target_ids_list): # set() per evitare duplicati sulla stessa riga\n",
    "        if not t_id: continue\n",
    "        \n",
    "        if t_id in secnum_lookup:\n",
    "            # MATCH TROVATO\n",
    "            positive_text = secnum_lookup[t_id]\n",
    "            \n",
    "            training_data.append({\n",
    "                'anchor_id': anchor_id,\n",
    "                'anchor_text': anchor_text,\n",
    "                'target_id': t_id,      # ID normalizzato\n",
    "                'target_text': positive_text,\n",
    "                'source': 'Cisco',\n",
    "                'target': 'SecNumCloud (EN)'\n",
    "            })\n",
    "            stats[\"matches\"] += 1\n",
    "        else:\n",
    "            # MATCH NON TROVATO (ID presente in Cisco ma non nel file SecNumCloud)\n",
    "            stats[\"missing\"].add(t_id)\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. SALVATAGGIO FILE STEP 2\n",
    "# ==============================================================================\n",
    "df_result = pd.DataFrame(training_data)\n",
    "df_result.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"RISULTATO STEP 2\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Nuove coppie generate: {len(df_result)}\")\n",
    "print(f\"Codici SecNumCloud non trovati: {len(stats['missing'])}\")\n",
    "if stats['missing']:\n",
    "    print(f\"Esempio mancanti: {list(stats['missing'])[:3]}...\")\n",
    "print(f\"\\nFile salvato: {OUTPUT_FILE}\")\n",
    "\n",
    "# Anteprima\n",
    "print(\"\\nAnteprima dati:\")\n",
    "print(df_result[['anchor_id', 'target_id', 'target_text']].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a25b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
